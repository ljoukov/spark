/* eslint-disable */
// @generated by protobuf-ts 2.9.6 with parameter eslint_disable,long_type_string,ts_nocheck
// @generated from protobuf file "SparkProto.proto" (syntax proto3)
// tslint:disable
// @ts-nocheck
import type { BinaryWriteOptions } from '@protobuf-ts/runtime';
import type { IBinaryWriter } from '@protobuf-ts/runtime';
import { WireType } from '@protobuf-ts/runtime';
import type { BinaryReadOptions } from '@protobuf-ts/runtime';
import type { IBinaryReader } from '@protobuf-ts/runtime';
import { UnknownFieldHandler } from '@protobuf-ts/runtime';
import type { PartialMessage } from '@protobuf-ts/runtime';
import { reflectionMergePartial } from '@protobuf-ts/runtime';
import { MessageType } from '@protobuf-ts/runtime';
import { Timestamp } from './google/protobuf/timestamp';
import { Duration } from './google/protobuf/duration';
/**
 * @generated from protobuf message SparkApiRequestProto
 */
export interface SparkApiRequestProto {
	/**
	 * @generated from protobuf field: SparkRequestAuthProto request_auth = 1;
	 */
	requestAuth?: SparkRequestAuthProto;
	/**
	 * @generated from protobuf field: SparkClientContextProto client_context = 2;
	 */
	clientContext?: SparkClientContextProto;
	/**
	 * @generated from protobuf oneof: request
	 */
	request:
		| {
				oneofKind: 'create';
				/**
				 * @generated from protobuf field: SparkCreateRequestProto create = 10;
				 */
				create: SparkCreateRequestProto;
		  }
		| {
				oneofKind: 'checkAnswer';
				/**
				 * @generated from protobuf field: SparkCheckAnswerRequestProto check_answer = 11;
				 */
				checkAnswer: SparkCheckAnswerRequestProto;
		  }
		| {
				oneofKind: undefined;
		  };
}
/**
 * @generated from protobuf message SparkApiResponseProto
 */
export interface SparkApiResponseProto {
	/**
	 * @generated from protobuf field: SparkApiErrorProto error = 1;
	 */
	error?: SparkApiErrorProto;
	/**
	 * @generated from protobuf oneof: response
	 */
	response:
		| {
				oneofKind: 'create';
				/**
				 * @generated from protobuf field: SparkCreateResponseProto create = 10;
				 */
				create: SparkCreateResponseProto;
		  }
		| {
				oneofKind: 'checkAnswer';
				/**
				 * @generated from protobuf field: SparkCheckAnswerResponseProto check_answer = 11;
				 */
				checkAnswer: SparkCheckAnswerResponseProto;
		  }
		| {
				oneofKind: undefined;
		  };
	/**
	 * @generated from protobuf field: map<string, google.protobuf.Duration> latencies = 100;
	 */
	latencies: {
		[key: string]: Duration;
	};
}
/**
 * @generated from protobuf message SparkCreateRequestProto
 */
export interface SparkCreateRequestProto {
	/**
	 * @generated from protobuf field: SparkUploadReferenceProto upload = 1;
	 */
	upload?: SparkUploadReferenceProto;
}
/**
 * @generated from protobuf message SparkCreateResponseProto
 */
export interface SparkCreateResponseProto {
	/**
	 * @generated from protobuf field: SparkJobStatusProto job = 1;
	 */
	job?: SparkJobStatusProto;
	/**
	 * @generated from protobuf field: SparkQuizProto quiz = 2;
	 */
	quiz?: SparkQuizProto;
}
/**
 * @generated from protobuf message SparkUploadReferenceProto
 */
export interface SparkUploadReferenceProto {
	/**
	 * @generated from protobuf field: string storage_path = 1;
	 */
	storagePath: string;
	/**
	 * @generated from protobuf field: SparkUploadTypeProto upload_type = 2;
	 */
	uploadType: SparkUploadTypeProto;
	/**
	 * @generated from protobuf field: string mime_type = 3;
	 */
	mimeType: string;
	/**
	 * @generated from protobuf field: int64 size_bytes = 4;
	 */
	sizeBytes: string;
	/**
	 * @generated from protobuf field: SparkPageRangeProto page_range = 5;
	 */
	pageRange?: SparkPageRangeProto;
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp uploaded_at = 6;
	 */
	uploadedAt?: Timestamp;
}
/**
 * @generated from protobuf message SparkPageRangeProto
 */
export interface SparkPageRangeProto {
	/**
	 * @generated from protobuf field: int32 start_page = 1;
	 */
	startPage: number;
	/**
	 * @generated from protobuf field: int32 end_page = 2;
	 */
	endPage: number;
}
/**
 * @generated from protobuf message SparkCheckAnswerRequestProto
 */
export interface SparkCheckAnswerRequestProto {
	/**
	 * @generated from protobuf field: string quiz_id = 1;
	 */
	quizId: string;
	/**
	 * @generated from protobuf field: string question_id = 2;
	 */
	questionId: string;
	/**
	 * @generated from protobuf field: SparkSubmittedAnswerProto answer = 3;
	 */
	answer?: SparkSubmittedAnswerProto;
	/**
	 * @generated from protobuf field: string attempt_id = 4;
	 */
	attemptId: string;
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp answered_at = 5;
	 */
	answeredAt?: Timestamp;
}
/**
 * @generated from protobuf message SparkCheckAnswerResponseProto
 */
export interface SparkCheckAnswerResponseProto {
	/**
	 * @generated from protobuf field: SparkAnswerEvaluationProto evaluation = 1;
	 */
	evaluation?: SparkAnswerEvaluationProto;
	/**
	 * @generated from protobuf field: SparkQuestionProto question = 2;
	 */
	question?: SparkQuestionProto;
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp evaluated_at = 3;
	 */
	evaluatedAt?: Timestamp;
}
/**
 * @generated from protobuf message SparkSubmittedAnswerProto
 */
export interface SparkSubmittedAnswerProto {
	/**
	 * @generated from protobuf oneof: value
	 */
	value:
		| {
				oneofKind: 'text';
				/**
				 * @generated from protobuf field: string text = 1;
				 */
				text: string;
		  }
		| {
				oneofKind: 'optionId';
				/**
				 * @generated from protobuf field: string option_id = 2;
				 */
				optionId: string;
		  }
		| {
				oneofKind: 'trueFalse';
				/**
				 * @generated from protobuf field: bool true_false = 3;
				 */
				trueFalse: boolean;
		  }
		| {
				oneofKind: 'numeric';
				/**
				 * @generated from protobuf field: SparkNumericSubmissionProto numeric = 4;
				 */
				numeric: SparkNumericSubmissionProto;
		  }
		| {
				oneofKind: undefined;
		  };
}
/**
 * @generated from protobuf message SparkNumericSubmissionProto
 */
export interface SparkNumericSubmissionProto {
	/**
	 * @generated from protobuf field: double value = 1;
	 */
	value: number;
	/**
	 * @generated from protobuf field: string unit = 2;
	 */
	unit: string;
	/**
	 * @generated from protobuf field: int32 significant_figures = 3;
	 */
	significantFigures: number;
}
/**
 * @generated from protobuf message SparkAnswerEvaluationProto
 */
export interface SparkAnswerEvaluationProto {
	/**
	 * @generated from protobuf field: SparkAnswerGradeProto grade = 1;
	 */
	grade: SparkAnswerGradeProto;
	/**
	 * @generated from protobuf field: string feedback = 2;
	 */
	feedback: string;
	/**
	 * @generated from protobuf field: double score = 3;
	 */
	score: number;
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp retry_available_at = 4;
	 */
	retryAvailableAt?: Timestamp;
}
/**
 * @generated from protobuf message SparkQuestionProto
 */
export interface SparkQuestionProto {
	/**
	 * @generated from protobuf field: string question_id = 1;
	 */
	questionId: string;
	/**
	 * @generated from protobuf field: SparkQuestionKindProto kind = 2;
	 */
	kind: SparkQuestionKindProto;
	/**
	 * @generated from protobuf field: string prompt = 3;
	 */
	prompt: string;
	/**
	 * @generated from protobuf field: SparkQuestionSourceProto source = 4;
	 */
	source?: SparkQuestionSourceProto;
	/**
	 * @generated from protobuf field: SparkQuestionAnswerKeyProto answer_key = 5;
	 */
	answerKey?: SparkQuestionAnswerKeyProto;
	/**
	 * @generated from protobuf field: repeated string hints = 6;
	 */
	hints: string[];
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp created_at = 7;
	 */
	createdAt?: Timestamp;
	/**
	 * @generated from protobuf oneof: body
	 */
	body:
		| {
				oneofKind: 'multipleChoice';
				/**
				 * @generated from protobuf field: SparkMultipleChoiceQuestionProto multiple_choice = 10;
				 */
				multipleChoice: SparkMultipleChoiceQuestionProto;
		  }
		| {
				oneofKind: 'trueFalse';
				/**
				 * @generated from protobuf field: SparkTrueFalseQuestionProto true_false = 11;
				 */
				trueFalse: SparkTrueFalseQuestionProto;
		  }
		| {
				oneofKind: 'shortText';
				/**
				 * @generated from protobuf field: SparkFreeTextQuestionProto short_text = 12;
				 */
				shortText: SparkFreeTextQuestionProto;
		  }
		| {
				oneofKind: 'numeric';
				/**
				 * @generated from protobuf field: SparkNumericQuestionProto numeric = 13;
				 */
				numeric: SparkNumericQuestionProto;
		  }
		| {
				oneofKind: undefined;
		  };
}
/**
 * @generated from protobuf message SparkQuestionSourceProto
 */
export interface SparkQuestionSourceProto {
	/**
	 * @generated from protobuf field: string upload_path = 1;
	 */
	uploadPath: string;
	/**
	 * @generated from protobuf field: SparkPageRangeProto page_range = 2;
	 */
	pageRange?: SparkPageRangeProto;
	/**
	 * @generated from protobuf field: string snippet = 3;
	 */
	snippet: string;
}
/**
 * @generated from protobuf message SparkQuestionAnswerKeyProto
 */
export interface SparkQuestionAnswerKeyProto {
	/**
	 * @generated from protobuf oneof: key
	 */
	key:
		| {
				oneofKind: 'multipleChoice';
				/**
				 * @generated from protobuf field: SparkMultipleChoiceAnswerKeyProto multiple_choice = 1;
				 */
				multipleChoice: SparkMultipleChoiceAnswerKeyProto;
		  }
		| {
				oneofKind: 'trueFalse';
				/**
				 * @generated from protobuf field: SparkTrueFalseAnswerKeyProto true_false = 2;
				 */
				trueFalse: SparkTrueFalseAnswerKeyProto;
		  }
		| {
				oneofKind: 'shortText';
				/**
				 * @generated from protobuf field: SparkFreeTextAnswerKeyProto short_text = 3;
				 */
				shortText: SparkFreeTextAnswerKeyProto;
		  }
		| {
				oneofKind: 'numeric';
				/**
				 * @generated from protobuf field: SparkNumericAnswerKeyProto numeric = 4;
				 */
				numeric: SparkNumericAnswerKeyProto;
		  }
		| {
				oneofKind: undefined;
		  };
}
/**
 * @generated from protobuf message SparkMultipleChoiceQuestionProto
 */
export interface SparkMultipleChoiceQuestionProto {
	/**
	 * @generated from protobuf field: repeated SparkMultipleChoiceOptionProto options = 1;
	 */
	options: SparkMultipleChoiceOptionProto[];
	/**
	 * @generated from protobuf field: bool shuffle_options = 2;
	 */
	shuffleOptions: boolean;
}
/**
 * @generated from protobuf message SparkMultipleChoiceOptionProto
 */
export interface SparkMultipleChoiceOptionProto {
	/**
	 * @generated from protobuf field: string option_id = 1;
	 */
	optionId: string;
	/**
	 * @generated from protobuf field: string text = 2;
	 */
	text: string;
}
/**
 * @generated from protobuf message SparkTrueFalseQuestionProto
 */
export interface SparkTrueFalseQuestionProto {
	/**
	 * @generated from protobuf field: string statement = 1;
	 */
	statement: string;
}
/**
 * @generated from protobuf message SparkFreeTextQuestionProto
 */
export interface SparkFreeTextQuestionProto {
	/**
	 * @generated from protobuf field: SparkFreeTextRubricProto rubric = 1;
	 */
	rubric?: SparkFreeTextRubricProto;
	/**
	 * @generated from protobuf field: repeated string key_points = 2;
	 */
	keyPoints: string[];
}
/**
 * @generated from protobuf message SparkFreeTextRubricProto
 */
export interface SparkFreeTextRubricProto {
	/**
	 * @generated from protobuf field: string overview = 1;
	 */
	overview: string;
	/**
	 * @generated from protobuf field: repeated string bullet_points = 2;
	 */
	bulletPoints: string[];
}
/**
 * @generated from protobuf message SparkNumericQuestionProto
 */
export interface SparkNumericQuestionProto {
	/**
	 * @generated from protobuf field: string prompt_suffix = 1;
	 */
	promptSuffix: string;
	/**
	 * @generated from protobuf field: SparkNumericAnswerRuleProto rule = 2;
	 */
	rule?: SparkNumericAnswerRuleProto;
}
/**
 * @generated from protobuf message SparkNumericAnswerRuleProto
 */
export interface SparkNumericAnswerRuleProto {
	/**
	 * @generated from protobuf field: double value = 1;
	 */
	value: number;
	/**
	 * @generated from protobuf field: string unit = 2;
	 */
	unit: string;
	/**
	 * @generated from protobuf field: SparkNumericToleranceTypeProto tolerance_type = 3;
	 */
	toleranceType: SparkNumericToleranceTypeProto;
	/**
	 * @generated from protobuf field: double tolerance = 4;
	 */
	tolerance: number;
	/**
	 * @generated from protobuf field: int32 significant_figures = 5;
	 */
	significantFigures: number;
}
/**
 * @generated from protobuf message SparkMultipleChoiceAnswerKeyProto
 */
export interface SparkMultipleChoiceAnswerKeyProto {
	/**
	 * @generated from protobuf field: string correct_option_id = 1;
	 */
	correctOptionId: string;
}
/**
 * @generated from protobuf message SparkTrueFalseAnswerKeyProto
 */
export interface SparkTrueFalseAnswerKeyProto {
	/**
	 * @generated from protobuf field: bool correct_value = 1;
	 */
	correctValue: boolean;
}
/**
 * @generated from protobuf message SparkFreeTextAnswerKeyProto
 */
export interface SparkFreeTextAnswerKeyProto {
	/**
	 * @generated from protobuf field: repeated string exemplar_answers = 1;
	 */
	exemplarAnswers: string[];
}
/**
 * @generated from protobuf message SparkNumericAnswerKeyProto
 */
export interface SparkNumericAnswerKeyProto {
	/**
	 * @generated from protobuf field: SparkNumericAnswerRuleProto expected = 1;
	 */
	expected?: SparkNumericAnswerRuleProto;
}
/**
 * @generated from protobuf message SparkQuizProto
 */
export interface SparkQuizProto {
	/**
	 * @generated from protobuf field: string quiz_id = 1;
	 */
	quizId: string;
	/**
	 * @generated from protobuf field: SparkQuizMetadataProto metadata = 2;
	 */
	metadata?: SparkQuizMetadataProto;
	/**
	 * @generated from protobuf field: repeated SparkQuestionProto questions = 3;
	 */
	questions: SparkQuestionProto[];
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp created_at = 4;
	 */
	createdAt?: Timestamp;
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp expires_at = 5;
	 */
	expiresAt?: Timestamp;
}
/**
 * @generated from protobuf message SparkQuizMetadataProto
 */
export interface SparkQuizMetadataProto {
	/**
	 * @generated from protobuf field: SparkProgrammeProto programme = 1;
	 */
	programme: SparkProgrammeProto;
	/**
	 * @generated from protobuf field: SparkSubjectProto subject = 2;
	 */
	subject: SparkSubjectProto;
	/**
	 * @generated from protobuf field: SparkExamBoardProto exam_board = 3;
	 */
	examBoard: SparkExamBoardProto;
	/**
	 * @generated from protobuf field: SparkGenerationModeProto generation_mode = 4;
	 */
	generationMode: SparkGenerationModeProto;
	/**
	 * @generated from protobuf field: int32 total_questions = 5;
	 */
	totalQuestions: number;
	/**
	 * @generated from protobuf field: string topic = 6;
	 */
	topic: string;
	/**
	 * @generated from protobuf field: string subtopic = 7;
	 */
	subtopic: string;
}
/**
 * @generated from protobuf message SparkJobStatusProto
 */
export interface SparkJobStatusProto {
	/**
	 * @generated from protobuf field: string job_id = 1;
	 */
	jobId: string;
	/**
	 * @generated from protobuf field: SparkJobStateProto state = 2;
	 */
	state: SparkJobStateProto;
	/**
	 * @generated from protobuf field: double progress_percent = 3;
	 */
	progressPercent: number;
	/**
	 * @generated from protobuf field: string status_message = 4;
	 */
	statusMessage: string;
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp updated_at = 5;
	 */
	updatedAt?: Timestamp;
	/**
	 * @generated from protobuf field: SparkJobErrorProto error = 6;
	 */
	error?: SparkJobErrorProto;
}
/**
 * @generated from protobuf message SparkJobErrorProto
 */
export interface SparkJobErrorProto {
	/**
	 * @generated from protobuf field: string code = 1;
	 */
	code: string;
	/**
	 * @generated from protobuf field: string message = 2;
	 */
	message: string;
	/**
	 * @generated from protobuf field: map<string, string> context = 3;
	 */
	context: {
		[key: string]: string;
	};
}
/**
 * @generated from protobuf message SparkFirestoreDocProto
 */
export interface SparkFirestoreDocProto {
	/**
	 * @generated from protobuf field: string doc_id = 1;
	 */
	docId: string;
	/**
	 * @generated from protobuf field: SparkUploadReferenceProto upload = 2;
	 */
	upload?: SparkUploadReferenceProto;
	/**
	 * @generated from protobuf field: SparkJobStatusProto job = 3;
	 */
	job?: SparkJobStatusProto;
	/**
	 * @generated from protobuf field: SparkQuizProto quiz = 4;
	 */
	quiz?: SparkQuizProto;
	/**
	 * @generated from protobuf field: SparkQuizSummaryProto summary = 5;
	 */
	summary?: SparkQuizSummaryProto;
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp created_at = 6;
	 */
	createdAt?: Timestamp;
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp updated_at = 7;
	 */
	updatedAt?: Timestamp;
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp expires_at = 8;
	 */
	expiresAt?: Timestamp;
}
/**
 * @generated from protobuf message SparkFirestoreStateProto
 */
export interface SparkFirestoreStateProto {
	/**
	 * @generated from protobuf field: map<string, SparkQuizStateProto> quiz_states = 1;
	 */
	quizStates: {
		[key: string]: SparkQuizStateProto;
	};
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp updated_at = 2;
	 */
	updatedAt?: Timestamp;
}
/**
 * @generated from protobuf message SparkQuizStateProto
 */
export interface SparkQuizStateProto {
	/**
	 * @generated from protobuf field: string quiz_id = 1;
	 */
	quizId: string;
	/**
	 * @generated from protobuf field: int32 questions_answered = 2;
	 */
	questionsAnswered: number;
	/**
	 * @generated from protobuf field: int32 questions_correct = 3;
	 */
	questionsCorrect: number;
	/**
	 * @generated from protobuf field: bool completed = 4;
	 */
	completed: boolean;
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp last_answered_at = 5;
	 */
	lastAnsweredAt?: Timestamp;
	/**
	 * @generated from protobuf field: double score = 6;
	 */
	score: number;
	/**
	 * @generated from protobuf field: SparkQuizStateStatusProto status = 7;
	 */
	status: SparkQuizStateStatusProto;
	/**
	 * @generated from protobuf field: SparkQuizReviewStatusProto review_status = 8;
	 */
	reviewStatus: SparkQuizReviewStatusProto;
	/**
	 * @generated from protobuf field: string current_question_id = 9;
	 */
	currentQuestionId: string;
	/**
	 * @generated from protobuf field: repeated string incorrect_question_ids = 10;
	 */
	incorrectQuestionIds: string[];
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp started_at = 11;
	 */
	startedAt?: Timestamp;
}
/**
 * @generated from protobuf message SparkSummarizeResponseProto
 */
export interface SparkSummarizeResponseProto {
	/**
	 * @generated from protobuf field: SparkQuizSummaryProto summary = 1;
	 */
	summary?: SparkQuizSummaryProto;
	/**
	 * @generated from protobuf field: google.protobuf.Timestamp summarized_at = 2;
	 */
	summarizedAt?: Timestamp;
}
/**
 * @generated from protobuf message SparkQuizSummaryProto
 */
export interface SparkQuizSummaryProto {
	/**
	 * @generated from protobuf field: string quiz_id = 1;
	 */
	quizId: string;
	/**
	 * @generated from protobuf field: string headline = 2;
	 */
	headline: string;
	/**
	 * @generated from protobuf field: repeated SparkSubjectSummaryProto subject_breakdown = 3;
	 */
	subjectBreakdown: SparkSubjectSummaryProto[];
	/**
	 * @generated from protobuf field: repeated SparkStudyRecommendationProto recommendations = 4;
	 */
	recommendations: SparkStudyRecommendationProto[];
}
/**
 * @generated from protobuf message SparkSubjectSummaryProto
 */
export interface SparkSubjectSummaryProto {
	/**
	 * @generated from protobuf field: SparkSubjectProto subject = 1;
	 */
	subject: SparkSubjectProto;
	/**
	 * @generated from protobuf field: double mastery_percent = 2;
	 */
	masteryPercent: number;
	/**
	 * @generated from protobuf field: string narrative = 3;
	 */
	narrative: string;
}
/**
 * @generated from protobuf message SparkStudyRecommendationProto
 */
export interface SparkStudyRecommendationProto {
	/**
	 * @generated from protobuf field: string recommendation_id = 1;
	 */
	recommendationId: string;
	/**
	 * @generated from protobuf field: string title = 2;
	 */
	title: string;
	/**
	 * @generated from protobuf field: string description = 3;
	 */
	description: string;
}
/**
 * @generated from protobuf message SparkApiErrorProto
 */
export interface SparkApiErrorProto {
	/**
	 * @generated from protobuf field: string code = 1;
	 */
	code: string;
	/**
	 * @generated from protobuf field: string message = 2;
	 */
	message: string;
	/**
	 * @generated from protobuf field: repeated string details = 3;
	 */
	details: string[];
}
/**
 * @generated from protobuf message SparkRequestAuthProto
 */
export interface SparkRequestAuthProto {
	/**
	 * @generated from protobuf field: string firebase_id_token = 1;
	 */
	firebaseIdToken: string;
	/**
	 * @generated from protobuf field: string appcheck_token = 2;
	 */
	appcheckToken: string;
	/**
	 * @generated from protobuf field: string user_id = 3;
	 */
	userId: string;
}
/**
 * @generated from protobuf message SparkClientContextProto
 */
export interface SparkClientContextProto {
	/**
	 * @generated from protobuf field: string api_version = 1;
	 */
	apiVersion: string;
	/**
	 * @generated from protobuf field: string client_version = 2;
	 */
	clientVersion: string;
	/**
	 * @generated from protobuf field: SparkClientDeviceProto device = 3;
	 */
	device?: SparkClientDeviceProto;
	/**
	 * @generated from protobuf field: bool beta_user = 4;
	 */
	betaUser: boolean;
	/**
	 * @generated from protobuf field: SparkRequestLocaleProto locale = 5;
	 */
	locale?: SparkRequestLocaleProto;
}
/**
 * @generated from protobuf message SparkClientDeviceProto
 */
export interface SparkClientDeviceProto {
	/**
	 * @generated from protobuf field: string platform = 1;
	 */
	platform: string;
	/**
	 * @generated from protobuf field: string os_version = 2;
	 */
	osVersion: string;
	/**
	 * @generated from protobuf field: string device_model = 3;
	 */
	deviceModel: string;
	/**
	 * @generated from protobuf field: bool is_simulator = 4;
	 */
	isSimulator: boolean;
	/**
	 * @generated from protobuf field: string app_build = 5;
	 */
	appBuild: string;
}
/**
 * @generated from protobuf message SparkRequestLocaleProto
 */
export interface SparkRequestLocaleProto {
	/**
	 * @generated from protobuf field: string language = 1;
	 */
	language: string;
	/**
	 * @generated from protobuf field: string region = 2;
	 */
	region: string;
	/**
	 * @generated from protobuf field: string time_zone = 3;
	 */
	timeZone: string;
}
/**
 * @generated from protobuf enum SparkUploadTypeProto
 */
export enum SparkUploadTypeProto {
	/**
	 * @generated from protobuf enum value: SPARK_UPLOAD_TYPE_PROTO_UNDEFINED = 0;
	 */
	UNDEFINED = 0,
	/**
	 * @generated from protobuf enum value: SPARK_UPLOAD_TYPE_PROTO_PHOTO = 1;
	 */
	PHOTO = 1,
	/**
	 * @generated from protobuf enum value: SPARK_UPLOAD_TYPE_PROTO_PDF_FULL = 2;
	 */
	PDF_FULL = 2,
	/**
	 * @generated from protobuf enum value: SPARK_UPLOAD_TYPE_PROTO_PDF_PAGE_RANGE = 3;
	 */
	PDF_PAGE_RANGE = 3
}
/**
 * @generated from protobuf enum SparkAnswerGradeProto
 */
export enum SparkAnswerGradeProto {
	/**
	 * @generated from protobuf enum value: SPARK_ANSWER_GRADE_PROTO_UNDEFINED = 0;
	 */
	UNDEFINED = 0,
	/**
	 * @generated from protobuf enum value: SPARK_ANSWER_GRADE_PROTO_CORRECT = 1;
	 */
	CORRECT = 1,
	/**
	 * @generated from protobuf enum value: SPARK_ANSWER_GRADE_PROTO_INCORRECT = 2;
	 */
	INCORRECT = 2,
	/**
	 * @generated from protobuf enum value: SPARK_ANSWER_GRADE_PROTO_PARTIAL = 3;
	 */
	PARTIAL = 3,
	/**
	 * @generated from protobuf enum value: SPARK_ANSWER_GRADE_PROTO_RETRY = 4;
	 */
	RETRY = 4
}
/**
 * @generated from protobuf enum SparkQuestionKindProto
 */
export enum SparkQuestionKindProto {
	/**
	 * @generated from protobuf enum value: SPARK_QUESTION_KIND_PROTO_UNDEFINED = 0;
	 */
	UNDEFINED = 0,
	/**
	 * @generated from protobuf enum value: SPARK_QUESTION_KIND_PROTO_MULTIPLE_CHOICE = 1;
	 */
	MULTIPLE_CHOICE = 1,
	/**
	 * @generated from protobuf enum value: SPARK_QUESTION_KIND_PROTO_TRUE_FALSE = 2;
	 */
	TRUE_FALSE = 2,
	/**
	 * @generated from protobuf enum value: SPARK_QUESTION_KIND_PROTO_SHORT_TEXT = 3;
	 */
	SHORT_TEXT = 3,
	/**
	 * @generated from protobuf enum value: SPARK_QUESTION_KIND_PROTO_NUMERIC = 4;
	 */
	NUMERIC = 4
}
/**
 * @generated from protobuf enum SparkNumericToleranceTypeProto
 */
export enum SparkNumericToleranceTypeProto {
	/**
	 * @generated from protobuf enum value: SPARK_NUMERIC_TOLERANCE_TYPE_PROTO_UNDEFINED = 0;
	 */
	UNDEFINED = 0,
	/**
	 * @generated from protobuf enum value: SPARK_NUMERIC_TOLERANCE_TYPE_PROTO_ABSOLUTE = 1;
	 */
	ABSOLUTE = 1,
	/**
	 * @generated from protobuf enum value: SPARK_NUMERIC_TOLERANCE_TYPE_PROTO_RELATIVE = 2;
	 */
	RELATIVE = 2
}
/**
 * @generated from protobuf enum SparkProgrammeProto
 */
export enum SparkProgrammeProto {
	/**
	 * @generated from protobuf enum value: SPARK_PROGRAMME_PROTO_UNDEFINED = 0;
	 */
	UNDEFINED = 0,
	/**
	 * @generated from protobuf enum value: SPARK_PROGRAMME_PROTO_GCSE_TRIPLE_SCIENCE = 1;
	 */
	GCSE_TRIPLE_SCIENCE = 1
}
/**
 * @generated from protobuf enum SparkSubjectProto
 */
export enum SparkSubjectProto {
	/**
	 * @generated from protobuf enum value: SPARK_SUBJECT_PROTO_UNDEFINED = 0;
	 */
	UNDEFINED = 0,
	/**
	 * @generated from protobuf enum value: SPARK_SUBJECT_PROTO_BIOLOGY = 1;
	 */
	BIOLOGY = 1,
	/**
	 * @generated from protobuf enum value: SPARK_SUBJECT_PROTO_CHEMISTRY = 2;
	 */
	CHEMISTRY = 2,
	/**
	 * @generated from protobuf enum value: SPARK_SUBJECT_PROTO_PHYSICS = 3;
	 */
	PHYSICS = 3
}
/**
 * @generated from protobuf enum SparkExamBoardProto
 */
export enum SparkExamBoardProto {
	/**
	 * @generated from protobuf enum value: SPARK_EXAM_BOARD_PROTO_UNDEFINED = 0;
	 */
	UNDEFINED = 0,
	/**
	 * @generated from protobuf enum value: SPARK_EXAM_BOARD_PROTO_AQA = 1;
	 */
	AQA = 1,
	/**
	 * @generated from protobuf enum value: SPARK_EXAM_BOARD_PROTO_EDEXCEL = 2;
	 */
	EDEXCEL = 2,
	/**
	 * @generated from protobuf enum value: SPARK_EXAM_BOARD_PROTO_OCR = 3;
	 */
	OCR = 3
}
/**
 * @generated from protobuf enum SparkGenerationModeProto
 */
export enum SparkGenerationModeProto {
	/**
	 * @generated from protobuf enum value: SPARK_GENERATION_MODE_PROTO_UNDEFINED = 0;
	 */
	UNDEFINED = 0,
	/**
	 * @generated from protobuf enum value: SPARK_GENERATION_MODE_PROTO_EXTRACTION = 1;
	 */
	EXTRACTION = 1,
	/**
	 * @generated from protobuf enum value: SPARK_GENERATION_MODE_PROTO_SYNTHESIS = 2;
	 */
	SYNTHESIS = 2
}
/**
 * @generated from protobuf enum SparkJobStateProto
 */
export enum SparkJobStateProto {
	/**
	 * @generated from protobuf enum value: SPARK_JOB_STATE_PROTO_UNDEFINED = 0;
	 */
	UNDEFINED = 0,
	/**
	 * @generated from protobuf enum value: SPARK_JOB_STATE_PROTO_RECEIVED = 1;
	 */
	RECEIVED = 1,
	/**
	 * @generated from protobuf enum value: SPARK_JOB_STATE_PROTO_PROCESSING = 2;
	 */
	PROCESSING = 2,
	/**
	 * @generated from protobuf enum value: SPARK_JOB_STATE_PROTO_COMPLETED = 3;
	 */
	COMPLETED = 3,
	/**
	 * @generated from protobuf enum value: SPARK_JOB_STATE_PROTO_FAILED = 4;
	 */
	FAILED = 4,
	/**
	 * @generated from protobuf enum value: SPARK_JOB_STATE_PROTO_CANCELLED = 5;
	 */
	CANCELLED = 5
}
/**
 * @generated from protobuf enum SparkQuizStateStatusProto
 */
export enum SparkQuizStateStatusProto {
	/**
	 * @generated from protobuf enum value: SPARK_QUIZ_STATE_STATUS_PROTO_UNDEFINED = 0;
	 */
	UNDEFINED = 0,
	/**
	 * @generated from protobuf enum value: SPARK_QUIZ_STATE_STATUS_PROTO_NOT_STARTED = 1;
	 */
	NOT_STARTED = 1,
	/**
	 * @generated from protobuf enum value: SPARK_QUIZ_STATE_STATUS_PROTO_IN_PROGRESS = 2;
	 */
	IN_PROGRESS = 2,
	/**
	 * @generated from protobuf enum value: SPARK_QUIZ_STATE_STATUS_PROTO_COMPLETED = 3;
	 */
	COMPLETED = 3,
	/**
	 * @generated from protobuf enum value: SPARK_QUIZ_STATE_STATUS_PROTO_ARCHIVED = 4;
	 */
	ARCHIVED = 4
}
/**
 * @generated from protobuf enum SparkQuizReviewStatusProto
 */
export enum SparkQuizReviewStatusProto {
	/**
	 * @generated from protobuf enum value: SPARK_QUIZ_REVIEW_STATUS_PROTO_UNDEFINED = 0;
	 */
	UNDEFINED = 0,
	/**
	 * @generated from protobuf enum value: SPARK_QUIZ_REVIEW_STATUS_PROTO_NOT_REQUIRED = 1;
	 */
	NOT_REQUIRED = 1,
	/**
	 * @generated from protobuf enum value: SPARK_QUIZ_REVIEW_STATUS_PROTO_PENDING = 2;
	 */
	PENDING = 2,
	/**
	 * @generated from protobuf enum value: SPARK_QUIZ_REVIEW_STATUS_PROTO_IN_REVIEW = 3;
	 */
	IN_REVIEW = 3,
	/**
	 * @generated from protobuf enum value: SPARK_QUIZ_REVIEW_STATUS_PROTO_DONE = 4;
	 */
	DONE = 4
}
// @generated message type with reflection information, may provide speed optimized methods
class SparkApiRequestProto$Type extends MessageType<SparkApiRequestProto> {
	constructor() {
		super('SparkApiRequestProto', [
			{ no: 1, name: 'request_auth', kind: 'message', T: () => SparkRequestAuthProto },
			{ no: 2, name: 'client_context', kind: 'message', T: () => SparkClientContextProto },
			{
				no: 10,
				name: 'create',
				kind: 'message',
				oneof: 'request',
				T: () => SparkCreateRequestProto
			},
			{
				no: 11,
				name: 'check_answer',
				kind: 'message',
				oneof: 'request',
				T: () => SparkCheckAnswerRequestProto
			}
		]);
	}
	create(value?: PartialMessage<SparkApiRequestProto>): SparkApiRequestProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.request = { oneofKind: undefined };
		if (value !== undefined) reflectionMergePartial<SparkApiRequestProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkApiRequestProto
	): SparkApiRequestProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* SparkRequestAuthProto request_auth */ 1:
					message.requestAuth = SparkRequestAuthProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.requestAuth
					);
					break;
				case /* SparkClientContextProto client_context */ 2:
					message.clientContext = SparkClientContextProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.clientContext
					);
					break;
				case /* SparkCreateRequestProto create */ 10:
					message.request = {
						oneofKind: 'create',
						create: SparkCreateRequestProto.internalBinaryRead(
							reader,
							reader.uint32(),
							options,
							(message.request as any).create
						)
					};
					break;
				case /* SparkCheckAnswerRequestProto check_answer */ 11:
					message.request = {
						oneofKind: 'checkAnswer',
						checkAnswer: SparkCheckAnswerRequestProto.internalBinaryRead(
							reader,
							reader.uint32(),
							options,
							(message.request as any).checkAnswer
						)
					};
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkApiRequestProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* SparkRequestAuthProto request_auth = 1; */
		if (message.requestAuth)
			SparkRequestAuthProto.internalBinaryWrite(
				message.requestAuth,
				writer.tag(1, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkClientContextProto client_context = 2; */
		if (message.clientContext)
			SparkClientContextProto.internalBinaryWrite(
				message.clientContext,
				writer.tag(2, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkCreateRequestProto create = 10; */
		if (message.request.oneofKind === 'create')
			SparkCreateRequestProto.internalBinaryWrite(
				message.request.create,
				writer.tag(10, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkCheckAnswerRequestProto check_answer = 11; */
		if (message.request.oneofKind === 'checkAnswer')
			SparkCheckAnswerRequestProto.internalBinaryWrite(
				message.request.checkAnswer,
				writer.tag(11, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkApiRequestProto
 */
export const SparkApiRequestProto = new SparkApiRequestProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkApiResponseProto$Type extends MessageType<SparkApiResponseProto> {
	constructor() {
		super('SparkApiResponseProto', [
			{ no: 1, name: 'error', kind: 'message', T: () => SparkApiErrorProto },
			{
				no: 10,
				name: 'create',
				kind: 'message',
				oneof: 'response',
				T: () => SparkCreateResponseProto
			},
			{
				no: 11,
				name: 'check_answer',
				kind: 'message',
				oneof: 'response',
				T: () => SparkCheckAnswerResponseProto
			},
			{
				no: 100,
				name: 'latencies',
				kind: 'map',
				K: 9 /*ScalarType.STRING*/,
				V: { kind: 'message', T: () => Duration }
			}
		]);
	}
	create(value?: PartialMessage<SparkApiResponseProto>): SparkApiResponseProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.response = { oneofKind: undefined };
		message.latencies = {};
		if (value !== undefined) reflectionMergePartial<SparkApiResponseProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkApiResponseProto
	): SparkApiResponseProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* SparkApiErrorProto error */ 1:
					message.error = SparkApiErrorProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.error
					);
					break;
				case /* SparkCreateResponseProto create */ 10:
					message.response = {
						oneofKind: 'create',
						create: SparkCreateResponseProto.internalBinaryRead(
							reader,
							reader.uint32(),
							options,
							(message.response as any).create
						)
					};
					break;
				case /* SparkCheckAnswerResponseProto check_answer */ 11:
					message.response = {
						oneofKind: 'checkAnswer',
						checkAnswer: SparkCheckAnswerResponseProto.internalBinaryRead(
							reader,
							reader.uint32(),
							options,
							(message.response as any).checkAnswer
						)
					};
					break;
				case /* map<string, google.protobuf.Duration> latencies */ 100:
					this.binaryReadMap100(message.latencies, reader, options);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	private binaryReadMap100(
		map: SparkApiResponseProto['latencies'],
		reader: IBinaryReader,
		options: BinaryReadOptions
	): void {
		let len = reader.uint32(),
			end = reader.pos + len,
			key: keyof SparkApiResponseProto['latencies'] | undefined,
			val: SparkApiResponseProto['latencies'][any] | undefined;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case 1:
					key = reader.string();
					break;
				case 2:
					val = Duration.internalBinaryRead(reader, reader.uint32(), options);
					break;
				default:
					throw new globalThis.Error(
						'unknown map entry field for field SparkApiResponseProto.latencies'
					);
			}
		}
		map[key ?? ''] = val ?? Duration.create();
	}
	internalBinaryWrite(
		message: SparkApiResponseProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* SparkApiErrorProto error = 1; */
		if (message.error)
			SparkApiErrorProto.internalBinaryWrite(
				message.error,
				writer.tag(1, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkCreateResponseProto create = 10; */
		if (message.response.oneofKind === 'create')
			SparkCreateResponseProto.internalBinaryWrite(
				message.response.create,
				writer.tag(10, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkCheckAnswerResponseProto check_answer = 11; */
		if (message.response.oneofKind === 'checkAnswer')
			SparkCheckAnswerResponseProto.internalBinaryWrite(
				message.response.checkAnswer,
				writer.tag(11, WireType.LengthDelimited).fork(),
				options
			).join();
		/* map<string, google.protobuf.Duration> latencies = 100; */
		for (let k of globalThis.Object.keys(message.latencies)) {
			writer.tag(100, WireType.LengthDelimited).fork().tag(1, WireType.LengthDelimited).string(k);
			writer.tag(2, WireType.LengthDelimited).fork();
			Duration.internalBinaryWrite(message.latencies[k], writer, options);
			writer.join().join();
		}
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkApiResponseProto
 */
export const SparkApiResponseProto = new SparkApiResponseProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkCreateRequestProto$Type extends MessageType<SparkCreateRequestProto> {
	constructor() {
		super('SparkCreateRequestProto', [
			{ no: 1, name: 'upload', kind: 'message', T: () => SparkUploadReferenceProto }
		]);
	}
	create(value?: PartialMessage<SparkCreateRequestProto>): SparkCreateRequestProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		if (value !== undefined) reflectionMergePartial<SparkCreateRequestProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkCreateRequestProto
	): SparkCreateRequestProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* SparkUploadReferenceProto upload */ 1:
					message.upload = SparkUploadReferenceProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.upload
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkCreateRequestProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* SparkUploadReferenceProto upload = 1; */
		if (message.upload)
			SparkUploadReferenceProto.internalBinaryWrite(
				message.upload,
				writer.tag(1, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkCreateRequestProto
 */
export const SparkCreateRequestProto = new SparkCreateRequestProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkCreateResponseProto$Type extends MessageType<SparkCreateResponseProto> {
	constructor() {
		super('SparkCreateResponseProto', [
			{ no: 1, name: 'job', kind: 'message', T: () => SparkJobStatusProto },
			{ no: 2, name: 'quiz', kind: 'message', T: () => SparkQuizProto }
		]);
	}
	create(value?: PartialMessage<SparkCreateResponseProto>): SparkCreateResponseProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		if (value !== undefined) reflectionMergePartial<SparkCreateResponseProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkCreateResponseProto
	): SparkCreateResponseProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* SparkJobStatusProto job */ 1:
					message.job = SparkJobStatusProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.job
					);
					break;
				case /* SparkQuizProto quiz */ 2:
					message.quiz = SparkQuizProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.quiz
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkCreateResponseProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* SparkJobStatusProto job = 1; */
		if (message.job)
			SparkJobStatusProto.internalBinaryWrite(
				message.job,
				writer.tag(1, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkQuizProto quiz = 2; */
		if (message.quiz)
			SparkQuizProto.internalBinaryWrite(
				message.quiz,
				writer.tag(2, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkCreateResponseProto
 */
export const SparkCreateResponseProto = new SparkCreateResponseProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkUploadReferenceProto$Type extends MessageType<SparkUploadReferenceProto> {
	constructor() {
		super('SparkUploadReferenceProto', [
			{ no: 1, name: 'storage_path', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{
				no: 2,
				name: 'upload_type',
				kind: 'enum',
				T: () => ['SparkUploadTypeProto', SparkUploadTypeProto, 'SPARK_UPLOAD_TYPE_PROTO_']
			},
			{ no: 3, name: 'mime_type', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 4, name: 'size_bytes', kind: 'scalar', T: 3 /*ScalarType.INT64*/ },
			{ no: 5, name: 'page_range', kind: 'message', T: () => SparkPageRangeProto },
			{ no: 6, name: 'uploaded_at', kind: 'message', T: () => Timestamp }
		]);
	}
	create(value?: PartialMessage<SparkUploadReferenceProto>): SparkUploadReferenceProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.storagePath = '';
		message.uploadType = 0;
		message.mimeType = '';
		message.sizeBytes = '0';
		if (value !== undefined)
			reflectionMergePartial<SparkUploadReferenceProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkUploadReferenceProto
	): SparkUploadReferenceProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string storage_path */ 1:
					message.storagePath = reader.string();
					break;
				case /* SparkUploadTypeProto upload_type */ 2:
					message.uploadType = reader.int32();
					break;
				case /* string mime_type */ 3:
					message.mimeType = reader.string();
					break;
				case /* int64 size_bytes */ 4:
					message.sizeBytes = reader.int64().toString();
					break;
				case /* SparkPageRangeProto page_range */ 5:
					message.pageRange = SparkPageRangeProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.pageRange
					);
					break;
				case /* google.protobuf.Timestamp uploaded_at */ 6:
					message.uploadedAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.uploadedAt
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkUploadReferenceProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string storage_path = 1; */
		if (message.storagePath !== '')
			writer.tag(1, WireType.LengthDelimited).string(message.storagePath);
		/* SparkUploadTypeProto upload_type = 2; */
		if (message.uploadType !== 0) writer.tag(2, WireType.Varint).int32(message.uploadType);
		/* string mime_type = 3; */
		if (message.mimeType !== '') writer.tag(3, WireType.LengthDelimited).string(message.mimeType);
		/* int64 size_bytes = 4; */
		if (message.sizeBytes !== '0') writer.tag(4, WireType.Varint).int64(message.sizeBytes);
		/* SparkPageRangeProto page_range = 5; */
		if (message.pageRange)
			SparkPageRangeProto.internalBinaryWrite(
				message.pageRange,
				writer.tag(5, WireType.LengthDelimited).fork(),
				options
			).join();
		/* google.protobuf.Timestamp uploaded_at = 6; */
		if (message.uploadedAt)
			Timestamp.internalBinaryWrite(
				message.uploadedAt,
				writer.tag(6, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkUploadReferenceProto
 */
export const SparkUploadReferenceProto = new SparkUploadReferenceProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkPageRangeProto$Type extends MessageType<SparkPageRangeProto> {
	constructor() {
		super('SparkPageRangeProto', [
			{ no: 1, name: 'start_page', kind: 'scalar', T: 5 /*ScalarType.INT32*/ },
			{ no: 2, name: 'end_page', kind: 'scalar', T: 5 /*ScalarType.INT32*/ }
		]);
	}
	create(value?: PartialMessage<SparkPageRangeProto>): SparkPageRangeProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.startPage = 0;
		message.endPage = 0;
		if (value !== undefined) reflectionMergePartial<SparkPageRangeProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkPageRangeProto
	): SparkPageRangeProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* int32 start_page */ 1:
					message.startPage = reader.int32();
					break;
				case /* int32 end_page */ 2:
					message.endPage = reader.int32();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkPageRangeProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* int32 start_page = 1; */
		if (message.startPage !== 0) writer.tag(1, WireType.Varint).int32(message.startPage);
		/* int32 end_page = 2; */
		if (message.endPage !== 0) writer.tag(2, WireType.Varint).int32(message.endPage);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkPageRangeProto
 */
export const SparkPageRangeProto = new SparkPageRangeProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkCheckAnswerRequestProto$Type extends MessageType<SparkCheckAnswerRequestProto> {
	constructor() {
		super('SparkCheckAnswerRequestProto', [
			{ no: 1, name: 'quiz_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'question_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 3, name: 'answer', kind: 'message', T: () => SparkSubmittedAnswerProto },
			{ no: 4, name: 'attempt_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 5, name: 'answered_at', kind: 'message', T: () => Timestamp }
		]);
	}
	create(value?: PartialMessage<SparkCheckAnswerRequestProto>): SparkCheckAnswerRequestProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.quizId = '';
		message.questionId = '';
		message.attemptId = '';
		if (value !== undefined)
			reflectionMergePartial<SparkCheckAnswerRequestProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkCheckAnswerRequestProto
	): SparkCheckAnswerRequestProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string quiz_id */ 1:
					message.quizId = reader.string();
					break;
				case /* string question_id */ 2:
					message.questionId = reader.string();
					break;
				case /* SparkSubmittedAnswerProto answer */ 3:
					message.answer = SparkSubmittedAnswerProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.answer
					);
					break;
				case /* string attempt_id */ 4:
					message.attemptId = reader.string();
					break;
				case /* google.protobuf.Timestamp answered_at */ 5:
					message.answeredAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.answeredAt
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkCheckAnswerRequestProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string quiz_id = 1; */
		if (message.quizId !== '') writer.tag(1, WireType.LengthDelimited).string(message.quizId);
		/* string question_id = 2; */
		if (message.questionId !== '')
			writer.tag(2, WireType.LengthDelimited).string(message.questionId);
		/* SparkSubmittedAnswerProto answer = 3; */
		if (message.answer)
			SparkSubmittedAnswerProto.internalBinaryWrite(
				message.answer,
				writer.tag(3, WireType.LengthDelimited).fork(),
				options
			).join();
		/* string attempt_id = 4; */
		if (message.attemptId !== '') writer.tag(4, WireType.LengthDelimited).string(message.attemptId);
		/* google.protobuf.Timestamp answered_at = 5; */
		if (message.answeredAt)
			Timestamp.internalBinaryWrite(
				message.answeredAt,
				writer.tag(5, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkCheckAnswerRequestProto
 */
export const SparkCheckAnswerRequestProto = new SparkCheckAnswerRequestProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkCheckAnswerResponseProto$Type extends MessageType<SparkCheckAnswerResponseProto> {
	constructor() {
		super('SparkCheckAnswerResponseProto', [
			{ no: 1, name: 'evaluation', kind: 'message', T: () => SparkAnswerEvaluationProto },
			{ no: 2, name: 'question', kind: 'message', T: () => SparkQuestionProto },
			{ no: 3, name: 'evaluated_at', kind: 'message', T: () => Timestamp }
		]);
	}
	create(value?: PartialMessage<SparkCheckAnswerResponseProto>): SparkCheckAnswerResponseProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		if (value !== undefined)
			reflectionMergePartial<SparkCheckAnswerResponseProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkCheckAnswerResponseProto
	): SparkCheckAnswerResponseProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* SparkAnswerEvaluationProto evaluation */ 1:
					message.evaluation = SparkAnswerEvaluationProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.evaluation
					);
					break;
				case /* SparkQuestionProto question */ 2:
					message.question = SparkQuestionProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.question
					);
					break;
				case /* google.protobuf.Timestamp evaluated_at */ 3:
					message.evaluatedAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.evaluatedAt
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkCheckAnswerResponseProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* SparkAnswerEvaluationProto evaluation = 1; */
		if (message.evaluation)
			SparkAnswerEvaluationProto.internalBinaryWrite(
				message.evaluation,
				writer.tag(1, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkQuestionProto question = 2; */
		if (message.question)
			SparkQuestionProto.internalBinaryWrite(
				message.question,
				writer.tag(2, WireType.LengthDelimited).fork(),
				options
			).join();
		/* google.protobuf.Timestamp evaluated_at = 3; */
		if (message.evaluatedAt)
			Timestamp.internalBinaryWrite(
				message.evaluatedAt,
				writer.tag(3, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkCheckAnswerResponseProto
 */
export const SparkCheckAnswerResponseProto = new SparkCheckAnswerResponseProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkSubmittedAnswerProto$Type extends MessageType<SparkSubmittedAnswerProto> {
	constructor() {
		super('SparkSubmittedAnswerProto', [
			{ no: 1, name: 'text', kind: 'scalar', oneof: 'value', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'option_id', kind: 'scalar', oneof: 'value', T: 9 /*ScalarType.STRING*/ },
			{ no: 3, name: 'true_false', kind: 'scalar', oneof: 'value', T: 8 /*ScalarType.BOOL*/ },
			{
				no: 4,
				name: 'numeric',
				kind: 'message',
				oneof: 'value',
				T: () => SparkNumericSubmissionProto
			}
		]);
	}
	create(value?: PartialMessage<SparkSubmittedAnswerProto>): SparkSubmittedAnswerProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.value = { oneofKind: undefined };
		if (value !== undefined)
			reflectionMergePartial<SparkSubmittedAnswerProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkSubmittedAnswerProto
	): SparkSubmittedAnswerProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string text */ 1:
					message.value = {
						oneofKind: 'text',
						text: reader.string()
					};
					break;
				case /* string option_id */ 2:
					message.value = {
						oneofKind: 'optionId',
						optionId: reader.string()
					};
					break;
				case /* bool true_false */ 3:
					message.value = {
						oneofKind: 'trueFalse',
						trueFalse: reader.bool()
					};
					break;
				case /* SparkNumericSubmissionProto numeric */ 4:
					message.value = {
						oneofKind: 'numeric',
						numeric: SparkNumericSubmissionProto.internalBinaryRead(
							reader,
							reader.uint32(),
							options,
							(message.value as any).numeric
						)
					};
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkSubmittedAnswerProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string text = 1; */
		if (message.value.oneofKind === 'text')
			writer.tag(1, WireType.LengthDelimited).string(message.value.text);
		/* string option_id = 2; */
		if (message.value.oneofKind === 'optionId')
			writer.tag(2, WireType.LengthDelimited).string(message.value.optionId);
		/* bool true_false = 3; */
		if (message.value.oneofKind === 'trueFalse')
			writer.tag(3, WireType.Varint).bool(message.value.trueFalse);
		/* SparkNumericSubmissionProto numeric = 4; */
		if (message.value.oneofKind === 'numeric')
			SparkNumericSubmissionProto.internalBinaryWrite(
				message.value.numeric,
				writer.tag(4, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkSubmittedAnswerProto
 */
export const SparkSubmittedAnswerProto = new SparkSubmittedAnswerProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkNumericSubmissionProto$Type extends MessageType<SparkNumericSubmissionProto> {
	constructor() {
		super('SparkNumericSubmissionProto', [
			{ no: 1, name: 'value', kind: 'scalar', T: 1 /*ScalarType.DOUBLE*/ },
			{ no: 2, name: 'unit', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 3, name: 'significant_figures', kind: 'scalar', T: 5 /*ScalarType.INT32*/ }
		]);
	}
	create(value?: PartialMessage<SparkNumericSubmissionProto>): SparkNumericSubmissionProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.value = 0;
		message.unit = '';
		message.significantFigures = 0;
		if (value !== undefined)
			reflectionMergePartial<SparkNumericSubmissionProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkNumericSubmissionProto
	): SparkNumericSubmissionProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* double value */ 1:
					message.value = reader.double();
					break;
				case /* string unit */ 2:
					message.unit = reader.string();
					break;
				case /* int32 significant_figures */ 3:
					message.significantFigures = reader.int32();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkNumericSubmissionProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* double value = 1; */
		if (message.value !== 0) writer.tag(1, WireType.Bit64).double(message.value);
		/* string unit = 2; */
		if (message.unit !== '') writer.tag(2, WireType.LengthDelimited).string(message.unit);
		/* int32 significant_figures = 3; */
		if (message.significantFigures !== 0)
			writer.tag(3, WireType.Varint).int32(message.significantFigures);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkNumericSubmissionProto
 */
export const SparkNumericSubmissionProto = new SparkNumericSubmissionProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkAnswerEvaluationProto$Type extends MessageType<SparkAnswerEvaluationProto> {
	constructor() {
		super('SparkAnswerEvaluationProto', [
			{
				no: 1,
				name: 'grade',
				kind: 'enum',
				T: () => ['SparkAnswerGradeProto', SparkAnswerGradeProto, 'SPARK_ANSWER_GRADE_PROTO_']
			},
			{ no: 2, name: 'feedback', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 3, name: 'score', kind: 'scalar', T: 1 /*ScalarType.DOUBLE*/ },
			{ no: 4, name: 'retry_available_at', kind: 'message', T: () => Timestamp }
		]);
	}
	create(value?: PartialMessage<SparkAnswerEvaluationProto>): SparkAnswerEvaluationProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.grade = 0;
		message.feedback = '';
		message.score = 0;
		if (value !== undefined)
			reflectionMergePartial<SparkAnswerEvaluationProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkAnswerEvaluationProto
	): SparkAnswerEvaluationProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* SparkAnswerGradeProto grade */ 1:
					message.grade = reader.int32();
					break;
				case /* string feedback */ 2:
					message.feedback = reader.string();
					break;
				case /* double score */ 3:
					message.score = reader.double();
					break;
				case /* google.protobuf.Timestamp retry_available_at */ 4:
					message.retryAvailableAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.retryAvailableAt
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkAnswerEvaluationProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* SparkAnswerGradeProto grade = 1; */
		if (message.grade !== 0) writer.tag(1, WireType.Varint).int32(message.grade);
		/* string feedback = 2; */
		if (message.feedback !== '') writer.tag(2, WireType.LengthDelimited).string(message.feedback);
		/* double score = 3; */
		if (message.score !== 0) writer.tag(3, WireType.Bit64).double(message.score);
		/* google.protobuf.Timestamp retry_available_at = 4; */
		if (message.retryAvailableAt)
			Timestamp.internalBinaryWrite(
				message.retryAvailableAt,
				writer.tag(4, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkAnswerEvaluationProto
 */
export const SparkAnswerEvaluationProto = new SparkAnswerEvaluationProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkQuestionProto$Type extends MessageType<SparkQuestionProto> {
	constructor() {
		super('SparkQuestionProto', [
			{ no: 1, name: 'question_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{
				no: 2,
				name: 'kind',
				kind: 'enum',
				T: () => ['SparkQuestionKindProto', SparkQuestionKindProto, 'SPARK_QUESTION_KIND_PROTO_']
			},
			{ no: 3, name: 'prompt', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 4, name: 'source', kind: 'message', T: () => SparkQuestionSourceProto },
			{ no: 5, name: 'answer_key', kind: 'message', T: () => SparkQuestionAnswerKeyProto },
			{
				no: 6,
				name: 'hints',
				kind: 'scalar',
				repeat: 2 /*RepeatType.UNPACKED*/,
				T: 9 /*ScalarType.STRING*/
			},
			{ no: 7, name: 'created_at', kind: 'message', T: () => Timestamp },
			{
				no: 10,
				name: 'multiple_choice',
				kind: 'message',
				oneof: 'body',
				T: () => SparkMultipleChoiceQuestionProto
			},
			{
				no: 11,
				name: 'true_false',
				kind: 'message',
				oneof: 'body',
				T: () => SparkTrueFalseQuestionProto
			},
			{
				no: 12,
				name: 'short_text',
				kind: 'message',
				oneof: 'body',
				T: () => SparkFreeTextQuestionProto
			},
			{
				no: 13,
				name: 'numeric',
				kind: 'message',
				oneof: 'body',
				T: () => SparkNumericQuestionProto
			}
		]);
	}
	create(value?: PartialMessage<SparkQuestionProto>): SparkQuestionProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.questionId = '';
		message.kind = 0;
		message.prompt = '';
		message.hints = [];
		message.body = { oneofKind: undefined };
		if (value !== undefined) reflectionMergePartial<SparkQuestionProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkQuestionProto
	): SparkQuestionProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string question_id */ 1:
					message.questionId = reader.string();
					break;
				case /* SparkQuestionKindProto kind */ 2:
					message.kind = reader.int32();
					break;
				case /* string prompt */ 3:
					message.prompt = reader.string();
					break;
				case /* SparkQuestionSourceProto source */ 4:
					message.source = SparkQuestionSourceProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.source
					);
					break;
				case /* SparkQuestionAnswerKeyProto answer_key */ 5:
					message.answerKey = SparkQuestionAnswerKeyProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.answerKey
					);
					break;
				case /* repeated string hints */ 6:
					message.hints.push(reader.string());
					break;
				case /* google.protobuf.Timestamp created_at */ 7:
					message.createdAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.createdAt
					);
					break;
				case /* SparkMultipleChoiceQuestionProto multiple_choice */ 10:
					message.body = {
						oneofKind: 'multipleChoice',
						multipleChoice: SparkMultipleChoiceQuestionProto.internalBinaryRead(
							reader,
							reader.uint32(),
							options,
							(message.body as any).multipleChoice
						)
					};
					break;
				case /* SparkTrueFalseQuestionProto true_false */ 11:
					message.body = {
						oneofKind: 'trueFalse',
						trueFalse: SparkTrueFalseQuestionProto.internalBinaryRead(
							reader,
							reader.uint32(),
							options,
							(message.body as any).trueFalse
						)
					};
					break;
				case /* SparkFreeTextQuestionProto short_text */ 12:
					message.body = {
						oneofKind: 'shortText',
						shortText: SparkFreeTextQuestionProto.internalBinaryRead(
							reader,
							reader.uint32(),
							options,
							(message.body as any).shortText
						)
					};
					break;
				case /* SparkNumericQuestionProto numeric */ 13:
					message.body = {
						oneofKind: 'numeric',
						numeric: SparkNumericQuestionProto.internalBinaryRead(
							reader,
							reader.uint32(),
							options,
							(message.body as any).numeric
						)
					};
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkQuestionProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string question_id = 1; */
		if (message.questionId !== '')
			writer.tag(1, WireType.LengthDelimited).string(message.questionId);
		/* SparkQuestionKindProto kind = 2; */
		if (message.kind !== 0) writer.tag(2, WireType.Varint).int32(message.kind);
		/* string prompt = 3; */
		if (message.prompt !== '') writer.tag(3, WireType.LengthDelimited).string(message.prompt);
		/* SparkQuestionSourceProto source = 4; */
		if (message.source)
			SparkQuestionSourceProto.internalBinaryWrite(
				message.source,
				writer.tag(4, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkQuestionAnswerKeyProto answer_key = 5; */
		if (message.answerKey)
			SparkQuestionAnswerKeyProto.internalBinaryWrite(
				message.answerKey,
				writer.tag(5, WireType.LengthDelimited).fork(),
				options
			).join();
		/* repeated string hints = 6; */
		for (let i = 0; i < message.hints.length; i++)
			writer.tag(6, WireType.LengthDelimited).string(message.hints[i]);
		/* google.protobuf.Timestamp created_at = 7; */
		if (message.createdAt)
			Timestamp.internalBinaryWrite(
				message.createdAt,
				writer.tag(7, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkMultipleChoiceQuestionProto multiple_choice = 10; */
		if (message.body.oneofKind === 'multipleChoice')
			SparkMultipleChoiceQuestionProto.internalBinaryWrite(
				message.body.multipleChoice,
				writer.tag(10, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkTrueFalseQuestionProto true_false = 11; */
		if (message.body.oneofKind === 'trueFalse')
			SparkTrueFalseQuestionProto.internalBinaryWrite(
				message.body.trueFalse,
				writer.tag(11, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkFreeTextQuestionProto short_text = 12; */
		if (message.body.oneofKind === 'shortText')
			SparkFreeTextQuestionProto.internalBinaryWrite(
				message.body.shortText,
				writer.tag(12, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkNumericQuestionProto numeric = 13; */
		if (message.body.oneofKind === 'numeric')
			SparkNumericQuestionProto.internalBinaryWrite(
				message.body.numeric,
				writer.tag(13, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkQuestionProto
 */
export const SparkQuestionProto = new SparkQuestionProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkQuestionSourceProto$Type extends MessageType<SparkQuestionSourceProto> {
	constructor() {
		super('SparkQuestionSourceProto', [
			{ no: 1, name: 'upload_path', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'page_range', kind: 'message', T: () => SparkPageRangeProto },
			{ no: 3, name: 'snippet', kind: 'scalar', T: 9 /*ScalarType.STRING*/ }
		]);
	}
	create(value?: PartialMessage<SparkQuestionSourceProto>): SparkQuestionSourceProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.uploadPath = '';
		message.snippet = '';
		if (value !== undefined) reflectionMergePartial<SparkQuestionSourceProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkQuestionSourceProto
	): SparkQuestionSourceProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string upload_path */ 1:
					message.uploadPath = reader.string();
					break;
				case /* SparkPageRangeProto page_range */ 2:
					message.pageRange = SparkPageRangeProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.pageRange
					);
					break;
				case /* string snippet */ 3:
					message.snippet = reader.string();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkQuestionSourceProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string upload_path = 1; */
		if (message.uploadPath !== '')
			writer.tag(1, WireType.LengthDelimited).string(message.uploadPath);
		/* SparkPageRangeProto page_range = 2; */
		if (message.pageRange)
			SparkPageRangeProto.internalBinaryWrite(
				message.pageRange,
				writer.tag(2, WireType.LengthDelimited).fork(),
				options
			).join();
		/* string snippet = 3; */
		if (message.snippet !== '') writer.tag(3, WireType.LengthDelimited).string(message.snippet);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkQuestionSourceProto
 */
export const SparkQuestionSourceProto = new SparkQuestionSourceProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkQuestionAnswerKeyProto$Type extends MessageType<SparkQuestionAnswerKeyProto> {
	constructor() {
		super('SparkQuestionAnswerKeyProto', [
			{
				no: 1,
				name: 'multiple_choice',
				kind: 'message',
				oneof: 'key',
				T: () => SparkMultipleChoiceAnswerKeyProto
			},
			{
				no: 2,
				name: 'true_false',
				kind: 'message',
				oneof: 'key',
				T: () => SparkTrueFalseAnswerKeyProto
			},
			{
				no: 3,
				name: 'short_text',
				kind: 'message',
				oneof: 'key',
				T: () => SparkFreeTextAnswerKeyProto
			},
			{ no: 4, name: 'numeric', kind: 'message', oneof: 'key', T: () => SparkNumericAnswerKeyProto }
		]);
	}
	create(value?: PartialMessage<SparkQuestionAnswerKeyProto>): SparkQuestionAnswerKeyProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.key = { oneofKind: undefined };
		if (value !== undefined)
			reflectionMergePartial<SparkQuestionAnswerKeyProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkQuestionAnswerKeyProto
	): SparkQuestionAnswerKeyProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* SparkMultipleChoiceAnswerKeyProto multiple_choice */ 1:
					message.key = {
						oneofKind: 'multipleChoice',
						multipleChoice: SparkMultipleChoiceAnswerKeyProto.internalBinaryRead(
							reader,
							reader.uint32(),
							options,
							(message.key as any).multipleChoice
						)
					};
					break;
				case /* SparkTrueFalseAnswerKeyProto true_false */ 2:
					message.key = {
						oneofKind: 'trueFalse',
						trueFalse: SparkTrueFalseAnswerKeyProto.internalBinaryRead(
							reader,
							reader.uint32(),
							options,
							(message.key as any).trueFalse
						)
					};
					break;
				case /* SparkFreeTextAnswerKeyProto short_text */ 3:
					message.key = {
						oneofKind: 'shortText',
						shortText: SparkFreeTextAnswerKeyProto.internalBinaryRead(
							reader,
							reader.uint32(),
							options,
							(message.key as any).shortText
						)
					};
					break;
				case /* SparkNumericAnswerKeyProto numeric */ 4:
					message.key = {
						oneofKind: 'numeric',
						numeric: SparkNumericAnswerKeyProto.internalBinaryRead(
							reader,
							reader.uint32(),
							options,
							(message.key as any).numeric
						)
					};
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkQuestionAnswerKeyProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* SparkMultipleChoiceAnswerKeyProto multiple_choice = 1; */
		if (message.key.oneofKind === 'multipleChoice')
			SparkMultipleChoiceAnswerKeyProto.internalBinaryWrite(
				message.key.multipleChoice,
				writer.tag(1, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkTrueFalseAnswerKeyProto true_false = 2; */
		if (message.key.oneofKind === 'trueFalse')
			SparkTrueFalseAnswerKeyProto.internalBinaryWrite(
				message.key.trueFalse,
				writer.tag(2, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkFreeTextAnswerKeyProto short_text = 3; */
		if (message.key.oneofKind === 'shortText')
			SparkFreeTextAnswerKeyProto.internalBinaryWrite(
				message.key.shortText,
				writer.tag(3, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkNumericAnswerKeyProto numeric = 4; */
		if (message.key.oneofKind === 'numeric')
			SparkNumericAnswerKeyProto.internalBinaryWrite(
				message.key.numeric,
				writer.tag(4, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkQuestionAnswerKeyProto
 */
export const SparkQuestionAnswerKeyProto = new SparkQuestionAnswerKeyProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkMultipleChoiceQuestionProto$Type extends MessageType<SparkMultipleChoiceQuestionProto> {
	constructor() {
		super('SparkMultipleChoiceQuestionProto', [
			{
				no: 1,
				name: 'options',
				kind: 'message',
				repeat: 1 /*RepeatType.PACKED*/,
				T: () => SparkMultipleChoiceOptionProto
			},
			{ no: 2, name: 'shuffle_options', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ }
		]);
	}
	create(
		value?: PartialMessage<SparkMultipleChoiceQuestionProto>
	): SparkMultipleChoiceQuestionProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.options = [];
		message.shuffleOptions = false;
		if (value !== undefined)
			reflectionMergePartial<SparkMultipleChoiceQuestionProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkMultipleChoiceQuestionProto
	): SparkMultipleChoiceQuestionProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* repeated SparkMultipleChoiceOptionProto options */ 1:
					message.options.push(
						SparkMultipleChoiceOptionProto.internalBinaryRead(reader, reader.uint32(), options)
					);
					break;
				case /* bool shuffle_options */ 2:
					message.shuffleOptions = reader.bool();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkMultipleChoiceQuestionProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* repeated SparkMultipleChoiceOptionProto options = 1; */
		for (let i = 0; i < message.options.length; i++)
			SparkMultipleChoiceOptionProto.internalBinaryWrite(
				message.options[i],
				writer.tag(1, WireType.LengthDelimited).fork(),
				options
			).join();
		/* bool shuffle_options = 2; */
		if (message.shuffleOptions !== false)
			writer.tag(2, WireType.Varint).bool(message.shuffleOptions);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkMultipleChoiceQuestionProto
 */
export const SparkMultipleChoiceQuestionProto = new SparkMultipleChoiceQuestionProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkMultipleChoiceOptionProto$Type extends MessageType<SparkMultipleChoiceOptionProto> {
	constructor() {
		super('SparkMultipleChoiceOptionProto', [
			{ no: 1, name: 'option_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'text', kind: 'scalar', T: 9 /*ScalarType.STRING*/ }
		]);
	}
	create(value?: PartialMessage<SparkMultipleChoiceOptionProto>): SparkMultipleChoiceOptionProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.optionId = '';
		message.text = '';
		if (value !== undefined)
			reflectionMergePartial<SparkMultipleChoiceOptionProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkMultipleChoiceOptionProto
	): SparkMultipleChoiceOptionProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string option_id */ 1:
					message.optionId = reader.string();
					break;
				case /* string text */ 2:
					message.text = reader.string();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkMultipleChoiceOptionProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string option_id = 1; */
		if (message.optionId !== '') writer.tag(1, WireType.LengthDelimited).string(message.optionId);
		/* string text = 2; */
		if (message.text !== '') writer.tag(2, WireType.LengthDelimited).string(message.text);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkMultipleChoiceOptionProto
 */
export const SparkMultipleChoiceOptionProto = new SparkMultipleChoiceOptionProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkTrueFalseQuestionProto$Type extends MessageType<SparkTrueFalseQuestionProto> {
	constructor() {
		super('SparkTrueFalseQuestionProto', [
			{ no: 1, name: 'statement', kind: 'scalar', T: 9 /*ScalarType.STRING*/ }
		]);
	}
	create(value?: PartialMessage<SparkTrueFalseQuestionProto>): SparkTrueFalseQuestionProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.statement = '';
		if (value !== undefined)
			reflectionMergePartial<SparkTrueFalseQuestionProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkTrueFalseQuestionProto
	): SparkTrueFalseQuestionProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string statement */ 1:
					message.statement = reader.string();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkTrueFalseQuestionProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string statement = 1; */
		if (message.statement !== '') writer.tag(1, WireType.LengthDelimited).string(message.statement);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkTrueFalseQuestionProto
 */
export const SparkTrueFalseQuestionProto = new SparkTrueFalseQuestionProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkFreeTextQuestionProto$Type extends MessageType<SparkFreeTextQuestionProto> {
	constructor() {
		super('SparkFreeTextQuestionProto', [
			{ no: 1, name: 'rubric', kind: 'message', T: () => SparkFreeTextRubricProto },
			{
				no: 2,
				name: 'key_points',
				kind: 'scalar',
				repeat: 2 /*RepeatType.UNPACKED*/,
				T: 9 /*ScalarType.STRING*/
			}
		]);
	}
	create(value?: PartialMessage<SparkFreeTextQuestionProto>): SparkFreeTextQuestionProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.keyPoints = [];
		if (value !== undefined)
			reflectionMergePartial<SparkFreeTextQuestionProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkFreeTextQuestionProto
	): SparkFreeTextQuestionProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* SparkFreeTextRubricProto rubric */ 1:
					message.rubric = SparkFreeTextRubricProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.rubric
					);
					break;
				case /* repeated string key_points */ 2:
					message.keyPoints.push(reader.string());
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkFreeTextQuestionProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* SparkFreeTextRubricProto rubric = 1; */
		if (message.rubric)
			SparkFreeTextRubricProto.internalBinaryWrite(
				message.rubric,
				writer.tag(1, WireType.LengthDelimited).fork(),
				options
			).join();
		/* repeated string key_points = 2; */
		for (let i = 0; i < message.keyPoints.length; i++)
			writer.tag(2, WireType.LengthDelimited).string(message.keyPoints[i]);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkFreeTextQuestionProto
 */
export const SparkFreeTextQuestionProto = new SparkFreeTextQuestionProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkFreeTextRubricProto$Type extends MessageType<SparkFreeTextRubricProto> {
	constructor() {
		super('SparkFreeTextRubricProto', [
			{ no: 1, name: 'overview', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{
				no: 2,
				name: 'bullet_points',
				kind: 'scalar',
				repeat: 2 /*RepeatType.UNPACKED*/,
				T: 9 /*ScalarType.STRING*/
			}
		]);
	}
	create(value?: PartialMessage<SparkFreeTextRubricProto>): SparkFreeTextRubricProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.overview = '';
		message.bulletPoints = [];
		if (value !== undefined) reflectionMergePartial<SparkFreeTextRubricProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkFreeTextRubricProto
	): SparkFreeTextRubricProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string overview */ 1:
					message.overview = reader.string();
					break;
				case /* repeated string bullet_points */ 2:
					message.bulletPoints.push(reader.string());
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkFreeTextRubricProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string overview = 1; */
		if (message.overview !== '') writer.tag(1, WireType.LengthDelimited).string(message.overview);
		/* repeated string bullet_points = 2; */
		for (let i = 0; i < message.bulletPoints.length; i++)
			writer.tag(2, WireType.LengthDelimited).string(message.bulletPoints[i]);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkFreeTextRubricProto
 */
export const SparkFreeTextRubricProto = new SparkFreeTextRubricProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkNumericQuestionProto$Type extends MessageType<SparkNumericQuestionProto> {
	constructor() {
		super('SparkNumericQuestionProto', [
			{ no: 1, name: 'prompt_suffix', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'rule', kind: 'message', T: () => SparkNumericAnswerRuleProto }
		]);
	}
	create(value?: PartialMessage<SparkNumericQuestionProto>): SparkNumericQuestionProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.promptSuffix = '';
		if (value !== undefined)
			reflectionMergePartial<SparkNumericQuestionProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkNumericQuestionProto
	): SparkNumericQuestionProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string prompt_suffix */ 1:
					message.promptSuffix = reader.string();
					break;
				case /* SparkNumericAnswerRuleProto rule */ 2:
					message.rule = SparkNumericAnswerRuleProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.rule
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkNumericQuestionProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string prompt_suffix = 1; */
		if (message.promptSuffix !== '')
			writer.tag(1, WireType.LengthDelimited).string(message.promptSuffix);
		/* SparkNumericAnswerRuleProto rule = 2; */
		if (message.rule)
			SparkNumericAnswerRuleProto.internalBinaryWrite(
				message.rule,
				writer.tag(2, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkNumericQuestionProto
 */
export const SparkNumericQuestionProto = new SparkNumericQuestionProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkNumericAnswerRuleProto$Type extends MessageType<SparkNumericAnswerRuleProto> {
	constructor() {
		super('SparkNumericAnswerRuleProto', [
			{ no: 1, name: 'value', kind: 'scalar', T: 1 /*ScalarType.DOUBLE*/ },
			{ no: 2, name: 'unit', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{
				no: 3,
				name: 'tolerance_type',
				kind: 'enum',
				T: () => [
					'SparkNumericToleranceTypeProto',
					SparkNumericToleranceTypeProto,
					'SPARK_NUMERIC_TOLERANCE_TYPE_PROTO_'
				]
			},
			{ no: 4, name: 'tolerance', kind: 'scalar', T: 1 /*ScalarType.DOUBLE*/ },
			{ no: 5, name: 'significant_figures', kind: 'scalar', T: 5 /*ScalarType.INT32*/ }
		]);
	}
	create(value?: PartialMessage<SparkNumericAnswerRuleProto>): SparkNumericAnswerRuleProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.value = 0;
		message.unit = '';
		message.toleranceType = 0;
		message.tolerance = 0;
		message.significantFigures = 0;
		if (value !== undefined)
			reflectionMergePartial<SparkNumericAnswerRuleProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkNumericAnswerRuleProto
	): SparkNumericAnswerRuleProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* double value */ 1:
					message.value = reader.double();
					break;
				case /* string unit */ 2:
					message.unit = reader.string();
					break;
				case /* SparkNumericToleranceTypeProto tolerance_type */ 3:
					message.toleranceType = reader.int32();
					break;
				case /* double tolerance */ 4:
					message.tolerance = reader.double();
					break;
				case /* int32 significant_figures */ 5:
					message.significantFigures = reader.int32();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkNumericAnswerRuleProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* double value = 1; */
		if (message.value !== 0) writer.tag(1, WireType.Bit64).double(message.value);
		/* string unit = 2; */
		if (message.unit !== '') writer.tag(2, WireType.LengthDelimited).string(message.unit);
		/* SparkNumericToleranceTypeProto tolerance_type = 3; */
		if (message.toleranceType !== 0) writer.tag(3, WireType.Varint).int32(message.toleranceType);
		/* double tolerance = 4; */
		if (message.tolerance !== 0) writer.tag(4, WireType.Bit64).double(message.tolerance);
		/* int32 significant_figures = 5; */
		if (message.significantFigures !== 0)
			writer.tag(5, WireType.Varint).int32(message.significantFigures);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkNumericAnswerRuleProto
 */
export const SparkNumericAnswerRuleProto = new SparkNumericAnswerRuleProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkMultipleChoiceAnswerKeyProto$Type extends MessageType<SparkMultipleChoiceAnswerKeyProto> {
	constructor() {
		super('SparkMultipleChoiceAnswerKeyProto', [
			{ no: 1, name: 'correct_option_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ }
		]);
	}
	create(
		value?: PartialMessage<SparkMultipleChoiceAnswerKeyProto>
	): SparkMultipleChoiceAnswerKeyProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.correctOptionId = '';
		if (value !== undefined)
			reflectionMergePartial<SparkMultipleChoiceAnswerKeyProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkMultipleChoiceAnswerKeyProto
	): SparkMultipleChoiceAnswerKeyProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string correct_option_id */ 1:
					message.correctOptionId = reader.string();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkMultipleChoiceAnswerKeyProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string correct_option_id = 1; */
		if (message.correctOptionId !== '')
			writer.tag(1, WireType.LengthDelimited).string(message.correctOptionId);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkMultipleChoiceAnswerKeyProto
 */
export const SparkMultipleChoiceAnswerKeyProto = new SparkMultipleChoiceAnswerKeyProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkTrueFalseAnswerKeyProto$Type extends MessageType<SparkTrueFalseAnswerKeyProto> {
	constructor() {
		super('SparkTrueFalseAnswerKeyProto', [
			{ no: 1, name: 'correct_value', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ }
		]);
	}
	create(value?: PartialMessage<SparkTrueFalseAnswerKeyProto>): SparkTrueFalseAnswerKeyProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.correctValue = false;
		if (value !== undefined)
			reflectionMergePartial<SparkTrueFalseAnswerKeyProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkTrueFalseAnswerKeyProto
	): SparkTrueFalseAnswerKeyProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* bool correct_value */ 1:
					message.correctValue = reader.bool();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkTrueFalseAnswerKeyProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* bool correct_value = 1; */
		if (message.correctValue !== false) writer.tag(1, WireType.Varint).bool(message.correctValue);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkTrueFalseAnswerKeyProto
 */
export const SparkTrueFalseAnswerKeyProto = new SparkTrueFalseAnswerKeyProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkFreeTextAnswerKeyProto$Type extends MessageType<SparkFreeTextAnswerKeyProto> {
	constructor() {
		super('SparkFreeTextAnswerKeyProto', [
			{
				no: 1,
				name: 'exemplar_answers',
				kind: 'scalar',
				repeat: 2 /*RepeatType.UNPACKED*/,
				T: 9 /*ScalarType.STRING*/
			}
		]);
	}
	create(value?: PartialMessage<SparkFreeTextAnswerKeyProto>): SparkFreeTextAnswerKeyProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.exemplarAnswers = [];
		if (value !== undefined)
			reflectionMergePartial<SparkFreeTextAnswerKeyProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkFreeTextAnswerKeyProto
	): SparkFreeTextAnswerKeyProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* repeated string exemplar_answers */ 1:
					message.exemplarAnswers.push(reader.string());
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkFreeTextAnswerKeyProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* repeated string exemplar_answers = 1; */
		for (let i = 0; i < message.exemplarAnswers.length; i++)
			writer.tag(1, WireType.LengthDelimited).string(message.exemplarAnswers[i]);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkFreeTextAnswerKeyProto
 */
export const SparkFreeTextAnswerKeyProto = new SparkFreeTextAnswerKeyProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkNumericAnswerKeyProto$Type extends MessageType<SparkNumericAnswerKeyProto> {
	constructor() {
		super('SparkNumericAnswerKeyProto', [
			{ no: 1, name: 'expected', kind: 'message', T: () => SparkNumericAnswerRuleProto }
		]);
	}
	create(value?: PartialMessage<SparkNumericAnswerKeyProto>): SparkNumericAnswerKeyProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		if (value !== undefined)
			reflectionMergePartial<SparkNumericAnswerKeyProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkNumericAnswerKeyProto
	): SparkNumericAnswerKeyProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* SparkNumericAnswerRuleProto expected */ 1:
					message.expected = SparkNumericAnswerRuleProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.expected
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkNumericAnswerKeyProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* SparkNumericAnswerRuleProto expected = 1; */
		if (message.expected)
			SparkNumericAnswerRuleProto.internalBinaryWrite(
				message.expected,
				writer.tag(1, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkNumericAnswerKeyProto
 */
export const SparkNumericAnswerKeyProto = new SparkNumericAnswerKeyProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkQuizProto$Type extends MessageType<SparkQuizProto> {
	constructor() {
		super('SparkQuizProto', [
			{ no: 1, name: 'quiz_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'metadata', kind: 'message', T: () => SparkQuizMetadataProto },
			{
				no: 3,
				name: 'questions',
				kind: 'message',
				repeat: 1 /*RepeatType.PACKED*/,
				T: () => SparkQuestionProto
			},
			{ no: 4, name: 'created_at', kind: 'message', T: () => Timestamp },
			{ no: 5, name: 'expires_at', kind: 'message', T: () => Timestamp }
		]);
	}
	create(value?: PartialMessage<SparkQuizProto>): SparkQuizProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.quizId = '';
		message.questions = [];
		if (value !== undefined) reflectionMergePartial<SparkQuizProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkQuizProto
	): SparkQuizProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string quiz_id */ 1:
					message.quizId = reader.string();
					break;
				case /* SparkQuizMetadataProto metadata */ 2:
					message.metadata = SparkQuizMetadataProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.metadata
					);
					break;
				case /* repeated SparkQuestionProto questions */ 3:
					message.questions.push(
						SparkQuestionProto.internalBinaryRead(reader, reader.uint32(), options)
					);
					break;
				case /* google.protobuf.Timestamp created_at */ 4:
					message.createdAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.createdAt
					);
					break;
				case /* google.protobuf.Timestamp expires_at */ 5:
					message.expiresAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.expiresAt
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkQuizProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string quiz_id = 1; */
		if (message.quizId !== '') writer.tag(1, WireType.LengthDelimited).string(message.quizId);
		/* SparkQuizMetadataProto metadata = 2; */
		if (message.metadata)
			SparkQuizMetadataProto.internalBinaryWrite(
				message.metadata,
				writer.tag(2, WireType.LengthDelimited).fork(),
				options
			).join();
		/* repeated SparkQuestionProto questions = 3; */
		for (let i = 0; i < message.questions.length; i++)
			SparkQuestionProto.internalBinaryWrite(
				message.questions[i],
				writer.tag(3, WireType.LengthDelimited).fork(),
				options
			).join();
		/* google.protobuf.Timestamp created_at = 4; */
		if (message.createdAt)
			Timestamp.internalBinaryWrite(
				message.createdAt,
				writer.tag(4, WireType.LengthDelimited).fork(),
				options
			).join();
		/* google.protobuf.Timestamp expires_at = 5; */
		if (message.expiresAt)
			Timestamp.internalBinaryWrite(
				message.expiresAt,
				writer.tag(5, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkQuizProto
 */
export const SparkQuizProto = new SparkQuizProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkQuizMetadataProto$Type extends MessageType<SparkQuizMetadataProto> {
	constructor() {
		super('SparkQuizMetadataProto', [
			{
				no: 1,
				name: 'programme',
				kind: 'enum',
				T: () => ['SparkProgrammeProto', SparkProgrammeProto, 'SPARK_PROGRAMME_PROTO_']
			},
			{
				no: 2,
				name: 'subject',
				kind: 'enum',
				T: () => ['SparkSubjectProto', SparkSubjectProto, 'SPARK_SUBJECT_PROTO_']
			},
			{
				no: 3,
				name: 'exam_board',
				kind: 'enum',
				T: () => ['SparkExamBoardProto', SparkExamBoardProto, 'SPARK_EXAM_BOARD_PROTO_']
			},
			{
				no: 4,
				name: 'generation_mode',
				kind: 'enum',
				T: () => [
					'SparkGenerationModeProto',
					SparkGenerationModeProto,
					'SPARK_GENERATION_MODE_PROTO_'
				]
			},
			{ no: 5, name: 'total_questions', kind: 'scalar', T: 5 /*ScalarType.INT32*/ },
			{ no: 6, name: 'topic', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 7, name: 'subtopic', kind: 'scalar', T: 9 /*ScalarType.STRING*/ }
		]);
	}
	create(value?: PartialMessage<SparkQuizMetadataProto>): SparkQuizMetadataProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.programme = 0;
		message.subject = 0;
		message.examBoard = 0;
		message.generationMode = 0;
		message.totalQuestions = 0;
		message.topic = '';
		message.subtopic = '';
		if (value !== undefined) reflectionMergePartial<SparkQuizMetadataProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkQuizMetadataProto
	): SparkQuizMetadataProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* SparkProgrammeProto programme */ 1:
					message.programme = reader.int32();
					break;
				case /* SparkSubjectProto subject */ 2:
					message.subject = reader.int32();
					break;
				case /* SparkExamBoardProto exam_board */ 3:
					message.examBoard = reader.int32();
					break;
				case /* SparkGenerationModeProto generation_mode */ 4:
					message.generationMode = reader.int32();
					break;
				case /* int32 total_questions */ 5:
					message.totalQuestions = reader.int32();
					break;
				case /* string topic */ 6:
					message.topic = reader.string();
					break;
				case /* string subtopic */ 7:
					message.subtopic = reader.string();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkQuizMetadataProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* SparkProgrammeProto programme = 1; */
		if (message.programme !== 0) writer.tag(1, WireType.Varint).int32(message.programme);
		/* SparkSubjectProto subject = 2; */
		if (message.subject !== 0) writer.tag(2, WireType.Varint).int32(message.subject);
		/* SparkExamBoardProto exam_board = 3; */
		if (message.examBoard !== 0) writer.tag(3, WireType.Varint).int32(message.examBoard);
		/* SparkGenerationModeProto generation_mode = 4; */
		if (message.generationMode !== 0) writer.tag(4, WireType.Varint).int32(message.generationMode);
		/* int32 total_questions = 5; */
		if (message.totalQuestions !== 0) writer.tag(5, WireType.Varint).int32(message.totalQuestions);
		/* string topic = 6; */
		if (message.topic !== '') writer.tag(6, WireType.LengthDelimited).string(message.topic);
		/* string subtopic = 7; */
		if (message.subtopic !== '') writer.tag(7, WireType.LengthDelimited).string(message.subtopic);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkQuizMetadataProto
 */
export const SparkQuizMetadataProto = new SparkQuizMetadataProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkJobStatusProto$Type extends MessageType<SparkJobStatusProto> {
	constructor() {
		super('SparkJobStatusProto', [
			{ no: 1, name: 'job_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{
				no: 2,
				name: 'state',
				kind: 'enum',
				T: () => ['SparkJobStateProto', SparkJobStateProto, 'SPARK_JOB_STATE_PROTO_']
			},
			{ no: 3, name: 'progress_percent', kind: 'scalar', T: 1 /*ScalarType.DOUBLE*/ },
			{ no: 4, name: 'status_message', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 5, name: 'updated_at', kind: 'message', T: () => Timestamp },
			{ no: 6, name: 'error', kind: 'message', T: () => SparkJobErrorProto }
		]);
	}
	create(value?: PartialMessage<SparkJobStatusProto>): SparkJobStatusProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.jobId = '';
		message.state = 0;
		message.progressPercent = 0;
		message.statusMessage = '';
		if (value !== undefined) reflectionMergePartial<SparkJobStatusProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkJobStatusProto
	): SparkJobStatusProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string job_id */ 1:
					message.jobId = reader.string();
					break;
				case /* SparkJobStateProto state */ 2:
					message.state = reader.int32();
					break;
				case /* double progress_percent */ 3:
					message.progressPercent = reader.double();
					break;
				case /* string status_message */ 4:
					message.statusMessage = reader.string();
					break;
				case /* google.protobuf.Timestamp updated_at */ 5:
					message.updatedAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.updatedAt
					);
					break;
				case /* SparkJobErrorProto error */ 6:
					message.error = SparkJobErrorProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.error
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkJobStatusProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string job_id = 1; */
		if (message.jobId !== '') writer.tag(1, WireType.LengthDelimited).string(message.jobId);
		/* SparkJobStateProto state = 2; */
		if (message.state !== 0) writer.tag(2, WireType.Varint).int32(message.state);
		/* double progress_percent = 3; */
		if (message.progressPercent !== 0)
			writer.tag(3, WireType.Bit64).double(message.progressPercent);
		/* string status_message = 4; */
		if (message.statusMessage !== '')
			writer.tag(4, WireType.LengthDelimited).string(message.statusMessage);
		/* google.protobuf.Timestamp updated_at = 5; */
		if (message.updatedAt)
			Timestamp.internalBinaryWrite(
				message.updatedAt,
				writer.tag(5, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkJobErrorProto error = 6; */
		if (message.error)
			SparkJobErrorProto.internalBinaryWrite(
				message.error,
				writer.tag(6, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkJobStatusProto
 */
export const SparkJobStatusProto = new SparkJobStatusProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkJobErrorProto$Type extends MessageType<SparkJobErrorProto> {
	constructor() {
		super('SparkJobErrorProto', [
			{ no: 1, name: 'code', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'message', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{
				no: 3,
				name: 'context',
				kind: 'map',
				K: 9 /*ScalarType.STRING*/,
				V: { kind: 'scalar', T: 9 /*ScalarType.STRING*/ }
			}
		]);
	}
	create(value?: PartialMessage<SparkJobErrorProto>): SparkJobErrorProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.code = '';
		message.message = '';
		message.context = {};
		if (value !== undefined) reflectionMergePartial<SparkJobErrorProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkJobErrorProto
	): SparkJobErrorProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string code */ 1:
					message.code = reader.string();
					break;
				case /* string message */ 2:
					message.message = reader.string();
					break;
				case /* map<string, string> context */ 3:
					this.binaryReadMap3(message.context, reader, options);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	private binaryReadMap3(
		map: SparkJobErrorProto['context'],
		reader: IBinaryReader,
		options: BinaryReadOptions
	): void {
		let len = reader.uint32(),
			end = reader.pos + len,
			key: keyof SparkJobErrorProto['context'] | undefined,
			val: SparkJobErrorProto['context'][any] | undefined;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case 1:
					key = reader.string();
					break;
				case 2:
					val = reader.string();
					break;
				default:
					throw new globalThis.Error(
						'unknown map entry field for field SparkJobErrorProto.context'
					);
			}
		}
		map[key ?? ''] = val ?? '';
	}
	internalBinaryWrite(
		message: SparkJobErrorProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string code = 1; */
		if (message.code !== '') writer.tag(1, WireType.LengthDelimited).string(message.code);
		/* string message = 2; */
		if (message.message !== '') writer.tag(2, WireType.LengthDelimited).string(message.message);
		/* map<string, string> context = 3; */
		for (let k of globalThis.Object.keys(message.context))
			writer
				.tag(3, WireType.LengthDelimited)
				.fork()
				.tag(1, WireType.LengthDelimited)
				.string(k)
				.tag(2, WireType.LengthDelimited)
				.string(message.context[k])
				.join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkJobErrorProto
 */
export const SparkJobErrorProto = new SparkJobErrorProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkFirestoreDocProto$Type extends MessageType<SparkFirestoreDocProto> {
	constructor() {
		super('SparkFirestoreDocProto', [
			{ no: 1, name: 'doc_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'upload', kind: 'message', T: () => SparkUploadReferenceProto },
			{ no: 3, name: 'job', kind: 'message', T: () => SparkJobStatusProto },
			{ no: 4, name: 'quiz', kind: 'message', T: () => SparkQuizProto },
			{ no: 5, name: 'summary', kind: 'message', T: () => SparkQuizSummaryProto },
			{ no: 6, name: 'created_at', kind: 'message', T: () => Timestamp },
			{ no: 7, name: 'updated_at', kind: 'message', T: () => Timestamp },
			{ no: 8, name: 'expires_at', kind: 'message', T: () => Timestamp }
		]);
	}
	create(value?: PartialMessage<SparkFirestoreDocProto>): SparkFirestoreDocProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.docId = '';
		if (value !== undefined) reflectionMergePartial<SparkFirestoreDocProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkFirestoreDocProto
	): SparkFirestoreDocProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string doc_id */ 1:
					message.docId = reader.string();
					break;
				case /* SparkUploadReferenceProto upload */ 2:
					message.upload = SparkUploadReferenceProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.upload
					);
					break;
				case /* SparkJobStatusProto job */ 3:
					message.job = SparkJobStatusProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.job
					);
					break;
				case /* SparkQuizProto quiz */ 4:
					message.quiz = SparkQuizProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.quiz
					);
					break;
				case /* SparkQuizSummaryProto summary */ 5:
					message.summary = SparkQuizSummaryProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.summary
					);
					break;
				case /* google.protobuf.Timestamp created_at */ 6:
					message.createdAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.createdAt
					);
					break;
				case /* google.protobuf.Timestamp updated_at */ 7:
					message.updatedAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.updatedAt
					);
					break;
				case /* google.protobuf.Timestamp expires_at */ 8:
					message.expiresAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.expiresAt
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkFirestoreDocProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string doc_id = 1; */
		if (message.docId !== '') writer.tag(1, WireType.LengthDelimited).string(message.docId);
		/* SparkUploadReferenceProto upload = 2; */
		if (message.upload)
			SparkUploadReferenceProto.internalBinaryWrite(
				message.upload,
				writer.tag(2, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkJobStatusProto job = 3; */
		if (message.job)
			SparkJobStatusProto.internalBinaryWrite(
				message.job,
				writer.tag(3, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkQuizProto quiz = 4; */
		if (message.quiz)
			SparkQuizProto.internalBinaryWrite(
				message.quiz,
				writer.tag(4, WireType.LengthDelimited).fork(),
				options
			).join();
		/* SparkQuizSummaryProto summary = 5; */
		if (message.summary)
			SparkQuizSummaryProto.internalBinaryWrite(
				message.summary,
				writer.tag(5, WireType.LengthDelimited).fork(),
				options
			).join();
		/* google.protobuf.Timestamp created_at = 6; */
		if (message.createdAt)
			Timestamp.internalBinaryWrite(
				message.createdAt,
				writer.tag(6, WireType.LengthDelimited).fork(),
				options
			).join();
		/* google.protobuf.Timestamp updated_at = 7; */
		if (message.updatedAt)
			Timestamp.internalBinaryWrite(
				message.updatedAt,
				writer.tag(7, WireType.LengthDelimited).fork(),
				options
			).join();
		/* google.protobuf.Timestamp expires_at = 8; */
		if (message.expiresAt)
			Timestamp.internalBinaryWrite(
				message.expiresAt,
				writer.tag(8, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkFirestoreDocProto
 */
export const SparkFirestoreDocProto = new SparkFirestoreDocProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkFirestoreStateProto$Type extends MessageType<SparkFirestoreStateProto> {
	constructor() {
		super('SparkFirestoreStateProto', [
			{
				no: 1,
				name: 'quiz_states',
				kind: 'map',
				K: 9 /*ScalarType.STRING*/,
				V: { kind: 'message', T: () => SparkQuizStateProto }
			},
			{ no: 2, name: 'updated_at', kind: 'message', T: () => Timestamp }
		]);
	}
	create(value?: PartialMessage<SparkFirestoreStateProto>): SparkFirestoreStateProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.quizStates = {};
		if (value !== undefined) reflectionMergePartial<SparkFirestoreStateProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkFirestoreStateProto
	): SparkFirestoreStateProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* map<string, SparkQuizStateProto> quiz_states */ 1:
					this.binaryReadMap1(message.quizStates, reader, options);
					break;
				case /* google.protobuf.Timestamp updated_at */ 2:
					message.updatedAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.updatedAt
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	private binaryReadMap1(
		map: SparkFirestoreStateProto['quizStates'],
		reader: IBinaryReader,
		options: BinaryReadOptions
	): void {
		let len = reader.uint32(),
			end = reader.pos + len,
			key: keyof SparkFirestoreStateProto['quizStates'] | undefined,
			val: SparkFirestoreStateProto['quizStates'][any] | undefined;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case 1:
					key = reader.string();
					break;
				case 2:
					val = SparkQuizStateProto.internalBinaryRead(reader, reader.uint32(), options);
					break;
				default:
					throw new globalThis.Error(
						'unknown map entry field for field SparkFirestoreStateProto.quiz_states'
					);
			}
		}
		map[key ?? ''] = val ?? SparkQuizStateProto.create();
	}
	internalBinaryWrite(
		message: SparkFirestoreStateProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* map<string, SparkQuizStateProto> quiz_states = 1; */
		for (let k of globalThis.Object.keys(message.quizStates)) {
			writer.tag(1, WireType.LengthDelimited).fork().tag(1, WireType.LengthDelimited).string(k);
			writer.tag(2, WireType.LengthDelimited).fork();
			SparkQuizStateProto.internalBinaryWrite(message.quizStates[k], writer, options);
			writer.join().join();
		}
		/* google.protobuf.Timestamp updated_at = 2; */
		if (message.updatedAt)
			Timestamp.internalBinaryWrite(
				message.updatedAt,
				writer.tag(2, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkFirestoreStateProto
 */
export const SparkFirestoreStateProto = new SparkFirestoreStateProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkQuizStateProto$Type extends MessageType<SparkQuizStateProto> {
	constructor() {
		super('SparkQuizStateProto', [
			{ no: 1, name: 'quiz_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'questions_answered', kind: 'scalar', T: 5 /*ScalarType.INT32*/ },
			{ no: 3, name: 'questions_correct', kind: 'scalar', T: 5 /*ScalarType.INT32*/ },
			{ no: 4, name: 'completed', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
			{ no: 5, name: 'last_answered_at', kind: 'message', T: () => Timestamp },
			{ no: 6, name: 'score', kind: 'scalar', T: 1 /*ScalarType.DOUBLE*/ },
			{
				no: 7,
				name: 'status',
				kind: 'enum',
				T: () => [
					'SparkQuizStateStatusProto',
					SparkQuizStateStatusProto,
					'SPARK_QUIZ_STATE_STATUS_PROTO_'
				]
			},
			{
				no: 8,
				name: 'review_status',
				kind: 'enum',
				T: () => [
					'SparkQuizReviewStatusProto',
					SparkQuizReviewStatusProto,
					'SPARK_QUIZ_REVIEW_STATUS_PROTO_'
				]
			},
			{ no: 9, name: 'current_question_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{
				no: 10,
				name: 'incorrect_question_ids',
				kind: 'scalar',
				repeat: 2 /*RepeatType.UNPACKED*/,
				T: 9 /*ScalarType.STRING*/
			},
			{ no: 11, name: 'started_at', kind: 'message', T: () => Timestamp }
		]);
	}
	create(value?: PartialMessage<SparkQuizStateProto>): SparkQuizStateProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.quizId = '';
		message.questionsAnswered = 0;
		message.questionsCorrect = 0;
		message.completed = false;
		message.score = 0;
		message.status = 0;
		message.reviewStatus = 0;
		message.currentQuestionId = '';
		message.incorrectQuestionIds = [];
		if (value !== undefined) reflectionMergePartial<SparkQuizStateProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkQuizStateProto
	): SparkQuizStateProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string quiz_id */ 1:
					message.quizId = reader.string();
					break;
				case /* int32 questions_answered */ 2:
					message.questionsAnswered = reader.int32();
					break;
				case /* int32 questions_correct */ 3:
					message.questionsCorrect = reader.int32();
					break;
				case /* bool completed */ 4:
					message.completed = reader.bool();
					break;
				case /* google.protobuf.Timestamp last_answered_at */ 5:
					message.lastAnsweredAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.lastAnsweredAt
					);
					break;
				case /* double score */ 6:
					message.score = reader.double();
					break;
				case /* SparkQuizStateStatusProto status */ 7:
					message.status = reader.int32();
					break;
				case /* SparkQuizReviewStatusProto review_status */ 8:
					message.reviewStatus = reader.int32();
					break;
				case /* string current_question_id */ 9:
					message.currentQuestionId = reader.string();
					break;
				case /* repeated string incorrect_question_ids */ 10:
					message.incorrectQuestionIds.push(reader.string());
					break;
				case /* google.protobuf.Timestamp started_at */ 11:
					message.startedAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.startedAt
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkQuizStateProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string quiz_id = 1; */
		if (message.quizId !== '') writer.tag(1, WireType.LengthDelimited).string(message.quizId);
		/* int32 questions_answered = 2; */
		if (message.questionsAnswered !== 0)
			writer.tag(2, WireType.Varint).int32(message.questionsAnswered);
		/* int32 questions_correct = 3; */
		if (message.questionsCorrect !== 0)
			writer.tag(3, WireType.Varint).int32(message.questionsCorrect);
		/* bool completed = 4; */
		if (message.completed !== false) writer.tag(4, WireType.Varint).bool(message.completed);
		/* google.protobuf.Timestamp last_answered_at = 5; */
		if (message.lastAnsweredAt)
			Timestamp.internalBinaryWrite(
				message.lastAnsweredAt,
				writer.tag(5, WireType.LengthDelimited).fork(),
				options
			).join();
		/* double score = 6; */
		if (message.score !== 0) writer.tag(6, WireType.Bit64).double(message.score);
		/* SparkQuizStateStatusProto status = 7; */
		if (message.status !== 0) writer.tag(7, WireType.Varint).int32(message.status);
		/* SparkQuizReviewStatusProto review_status = 8; */
		if (message.reviewStatus !== 0) writer.tag(8, WireType.Varint).int32(message.reviewStatus);
		/* string current_question_id = 9; */
		if (message.currentQuestionId !== '')
			writer.tag(9, WireType.LengthDelimited).string(message.currentQuestionId);
		/* repeated string incorrect_question_ids = 10; */
		for (let i = 0; i < message.incorrectQuestionIds.length; i++)
			writer.tag(10, WireType.LengthDelimited).string(message.incorrectQuestionIds[i]);
		/* google.protobuf.Timestamp started_at = 11; */
		if (message.startedAt)
			Timestamp.internalBinaryWrite(
				message.startedAt,
				writer.tag(11, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkQuizStateProto
 */
export const SparkQuizStateProto = new SparkQuizStateProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkSummarizeResponseProto$Type extends MessageType<SparkSummarizeResponseProto> {
	constructor() {
		super('SparkSummarizeResponseProto', [
			{ no: 1, name: 'summary', kind: 'message', T: () => SparkQuizSummaryProto },
			{ no: 2, name: 'summarized_at', kind: 'message', T: () => Timestamp }
		]);
	}
	create(value?: PartialMessage<SparkSummarizeResponseProto>): SparkSummarizeResponseProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		if (value !== undefined)
			reflectionMergePartial<SparkSummarizeResponseProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkSummarizeResponseProto
	): SparkSummarizeResponseProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* SparkQuizSummaryProto summary */ 1:
					message.summary = SparkQuizSummaryProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.summary
					);
					break;
				case /* google.protobuf.Timestamp summarized_at */ 2:
					message.summarizedAt = Timestamp.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.summarizedAt
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkSummarizeResponseProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* SparkQuizSummaryProto summary = 1; */
		if (message.summary)
			SparkQuizSummaryProto.internalBinaryWrite(
				message.summary,
				writer.tag(1, WireType.LengthDelimited).fork(),
				options
			).join();
		/* google.protobuf.Timestamp summarized_at = 2; */
		if (message.summarizedAt)
			Timestamp.internalBinaryWrite(
				message.summarizedAt,
				writer.tag(2, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkSummarizeResponseProto
 */
export const SparkSummarizeResponseProto = new SparkSummarizeResponseProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkQuizSummaryProto$Type extends MessageType<SparkQuizSummaryProto> {
	constructor() {
		super('SparkQuizSummaryProto', [
			{ no: 1, name: 'quiz_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'headline', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{
				no: 3,
				name: 'subject_breakdown',
				kind: 'message',
				repeat: 1 /*RepeatType.PACKED*/,
				T: () => SparkSubjectSummaryProto
			},
			{
				no: 4,
				name: 'recommendations',
				kind: 'message',
				repeat: 1 /*RepeatType.PACKED*/,
				T: () => SparkStudyRecommendationProto
			}
		]);
	}
	create(value?: PartialMessage<SparkQuizSummaryProto>): SparkQuizSummaryProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.quizId = '';
		message.headline = '';
		message.subjectBreakdown = [];
		message.recommendations = [];
		if (value !== undefined) reflectionMergePartial<SparkQuizSummaryProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkQuizSummaryProto
	): SparkQuizSummaryProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string quiz_id */ 1:
					message.quizId = reader.string();
					break;
				case /* string headline */ 2:
					message.headline = reader.string();
					break;
				case /* repeated SparkSubjectSummaryProto subject_breakdown */ 3:
					message.subjectBreakdown.push(
						SparkSubjectSummaryProto.internalBinaryRead(reader, reader.uint32(), options)
					);
					break;
				case /* repeated SparkStudyRecommendationProto recommendations */ 4:
					message.recommendations.push(
						SparkStudyRecommendationProto.internalBinaryRead(reader, reader.uint32(), options)
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkQuizSummaryProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string quiz_id = 1; */
		if (message.quizId !== '') writer.tag(1, WireType.LengthDelimited).string(message.quizId);
		/* string headline = 2; */
		if (message.headline !== '') writer.tag(2, WireType.LengthDelimited).string(message.headline);
		/* repeated SparkSubjectSummaryProto subject_breakdown = 3; */
		for (let i = 0; i < message.subjectBreakdown.length; i++)
			SparkSubjectSummaryProto.internalBinaryWrite(
				message.subjectBreakdown[i],
				writer.tag(3, WireType.LengthDelimited).fork(),
				options
			).join();
		/* repeated SparkStudyRecommendationProto recommendations = 4; */
		for (let i = 0; i < message.recommendations.length; i++)
			SparkStudyRecommendationProto.internalBinaryWrite(
				message.recommendations[i],
				writer.tag(4, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkQuizSummaryProto
 */
export const SparkQuizSummaryProto = new SparkQuizSummaryProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkSubjectSummaryProto$Type extends MessageType<SparkSubjectSummaryProto> {
	constructor() {
		super('SparkSubjectSummaryProto', [
			{
				no: 1,
				name: 'subject',
				kind: 'enum',
				T: () => ['SparkSubjectProto', SparkSubjectProto, 'SPARK_SUBJECT_PROTO_']
			},
			{ no: 2, name: 'mastery_percent', kind: 'scalar', T: 1 /*ScalarType.DOUBLE*/ },
			{ no: 3, name: 'narrative', kind: 'scalar', T: 9 /*ScalarType.STRING*/ }
		]);
	}
	create(value?: PartialMessage<SparkSubjectSummaryProto>): SparkSubjectSummaryProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.subject = 0;
		message.masteryPercent = 0;
		message.narrative = '';
		if (value !== undefined) reflectionMergePartial<SparkSubjectSummaryProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkSubjectSummaryProto
	): SparkSubjectSummaryProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* SparkSubjectProto subject */ 1:
					message.subject = reader.int32();
					break;
				case /* double mastery_percent */ 2:
					message.masteryPercent = reader.double();
					break;
				case /* string narrative */ 3:
					message.narrative = reader.string();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkSubjectSummaryProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* SparkSubjectProto subject = 1; */
		if (message.subject !== 0) writer.tag(1, WireType.Varint).int32(message.subject);
		/* double mastery_percent = 2; */
		if (message.masteryPercent !== 0) writer.tag(2, WireType.Bit64).double(message.masteryPercent);
		/* string narrative = 3; */
		if (message.narrative !== '') writer.tag(3, WireType.LengthDelimited).string(message.narrative);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkSubjectSummaryProto
 */
export const SparkSubjectSummaryProto = new SparkSubjectSummaryProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkStudyRecommendationProto$Type extends MessageType<SparkStudyRecommendationProto> {
	constructor() {
		super('SparkStudyRecommendationProto', [
			{ no: 1, name: 'recommendation_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'title', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 3, name: 'description', kind: 'scalar', T: 9 /*ScalarType.STRING*/ }
		]);
	}
	create(value?: PartialMessage<SparkStudyRecommendationProto>): SparkStudyRecommendationProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.recommendationId = '';
		message.title = '';
		message.description = '';
		if (value !== undefined)
			reflectionMergePartial<SparkStudyRecommendationProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkStudyRecommendationProto
	): SparkStudyRecommendationProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string recommendation_id */ 1:
					message.recommendationId = reader.string();
					break;
				case /* string title */ 2:
					message.title = reader.string();
					break;
				case /* string description */ 3:
					message.description = reader.string();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkStudyRecommendationProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string recommendation_id = 1; */
		if (message.recommendationId !== '')
			writer.tag(1, WireType.LengthDelimited).string(message.recommendationId);
		/* string title = 2; */
		if (message.title !== '') writer.tag(2, WireType.LengthDelimited).string(message.title);
		/* string description = 3; */
		if (message.description !== '')
			writer.tag(3, WireType.LengthDelimited).string(message.description);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkStudyRecommendationProto
 */
export const SparkStudyRecommendationProto = new SparkStudyRecommendationProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkApiErrorProto$Type extends MessageType<SparkApiErrorProto> {
	constructor() {
		super('SparkApiErrorProto', [
			{ no: 1, name: 'code', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'message', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{
				no: 3,
				name: 'details',
				kind: 'scalar',
				repeat: 2 /*RepeatType.UNPACKED*/,
				T: 9 /*ScalarType.STRING*/
			}
		]);
	}
	create(value?: PartialMessage<SparkApiErrorProto>): SparkApiErrorProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.code = '';
		message.message = '';
		message.details = [];
		if (value !== undefined) reflectionMergePartial<SparkApiErrorProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkApiErrorProto
	): SparkApiErrorProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string code */ 1:
					message.code = reader.string();
					break;
				case /* string message */ 2:
					message.message = reader.string();
					break;
				case /* repeated string details */ 3:
					message.details.push(reader.string());
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkApiErrorProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string code = 1; */
		if (message.code !== '') writer.tag(1, WireType.LengthDelimited).string(message.code);
		/* string message = 2; */
		if (message.message !== '') writer.tag(2, WireType.LengthDelimited).string(message.message);
		/* repeated string details = 3; */
		for (let i = 0; i < message.details.length; i++)
			writer.tag(3, WireType.LengthDelimited).string(message.details[i]);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkApiErrorProto
 */
export const SparkApiErrorProto = new SparkApiErrorProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkRequestAuthProto$Type extends MessageType<SparkRequestAuthProto> {
	constructor() {
		super('SparkRequestAuthProto', [
			{ no: 1, name: 'firebase_id_token', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'appcheck_token', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 3, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ }
		]);
	}
	create(value?: PartialMessage<SparkRequestAuthProto>): SparkRequestAuthProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.firebaseIdToken = '';
		message.appcheckToken = '';
		message.userId = '';
		if (value !== undefined) reflectionMergePartial<SparkRequestAuthProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkRequestAuthProto
	): SparkRequestAuthProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string firebase_id_token */ 1:
					message.firebaseIdToken = reader.string();
					break;
				case /* string appcheck_token */ 2:
					message.appcheckToken = reader.string();
					break;
				case /* string user_id */ 3:
					message.userId = reader.string();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkRequestAuthProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string firebase_id_token = 1; */
		if (message.firebaseIdToken !== '')
			writer.tag(1, WireType.LengthDelimited).string(message.firebaseIdToken);
		/* string appcheck_token = 2; */
		if (message.appcheckToken !== '')
			writer.tag(2, WireType.LengthDelimited).string(message.appcheckToken);
		/* string user_id = 3; */
		if (message.userId !== '') writer.tag(3, WireType.LengthDelimited).string(message.userId);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkRequestAuthProto
 */
export const SparkRequestAuthProto = new SparkRequestAuthProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkClientContextProto$Type extends MessageType<SparkClientContextProto> {
	constructor() {
		super('SparkClientContextProto', [
			{ no: 1, name: 'api_version', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'client_version', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 3, name: 'device', kind: 'message', T: () => SparkClientDeviceProto },
			{ no: 4, name: 'beta_user', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
			{ no: 5, name: 'locale', kind: 'message', T: () => SparkRequestLocaleProto }
		]);
	}
	create(value?: PartialMessage<SparkClientContextProto>): SparkClientContextProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.apiVersion = '';
		message.clientVersion = '';
		message.betaUser = false;
		if (value !== undefined) reflectionMergePartial<SparkClientContextProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkClientContextProto
	): SparkClientContextProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string api_version */ 1:
					message.apiVersion = reader.string();
					break;
				case /* string client_version */ 2:
					message.clientVersion = reader.string();
					break;
				case /* SparkClientDeviceProto device */ 3:
					message.device = SparkClientDeviceProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.device
					);
					break;
				case /* bool beta_user */ 4:
					message.betaUser = reader.bool();
					break;
				case /* SparkRequestLocaleProto locale */ 5:
					message.locale = SparkRequestLocaleProto.internalBinaryRead(
						reader,
						reader.uint32(),
						options,
						message.locale
					);
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkClientContextProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string api_version = 1; */
		if (message.apiVersion !== '')
			writer.tag(1, WireType.LengthDelimited).string(message.apiVersion);
		/* string client_version = 2; */
		if (message.clientVersion !== '')
			writer.tag(2, WireType.LengthDelimited).string(message.clientVersion);
		/* SparkClientDeviceProto device = 3; */
		if (message.device)
			SparkClientDeviceProto.internalBinaryWrite(
				message.device,
				writer.tag(3, WireType.LengthDelimited).fork(),
				options
			).join();
		/* bool beta_user = 4; */
		if (message.betaUser !== false) writer.tag(4, WireType.Varint).bool(message.betaUser);
		/* SparkRequestLocaleProto locale = 5; */
		if (message.locale)
			SparkRequestLocaleProto.internalBinaryWrite(
				message.locale,
				writer.tag(5, WireType.LengthDelimited).fork(),
				options
			).join();
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkClientContextProto
 */
export const SparkClientContextProto = new SparkClientContextProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkClientDeviceProto$Type extends MessageType<SparkClientDeviceProto> {
	constructor() {
		super('SparkClientDeviceProto', [
			{ no: 1, name: 'platform', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'os_version', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 3, name: 'device_model', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 4, name: 'is_simulator', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
			{ no: 5, name: 'app_build', kind: 'scalar', T: 9 /*ScalarType.STRING*/ }
		]);
	}
	create(value?: PartialMessage<SparkClientDeviceProto>): SparkClientDeviceProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.platform = '';
		message.osVersion = '';
		message.deviceModel = '';
		message.isSimulator = false;
		message.appBuild = '';
		if (value !== undefined) reflectionMergePartial<SparkClientDeviceProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkClientDeviceProto
	): SparkClientDeviceProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string platform */ 1:
					message.platform = reader.string();
					break;
				case /* string os_version */ 2:
					message.osVersion = reader.string();
					break;
				case /* string device_model */ 3:
					message.deviceModel = reader.string();
					break;
				case /* bool is_simulator */ 4:
					message.isSimulator = reader.bool();
					break;
				case /* string app_build */ 5:
					message.appBuild = reader.string();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkClientDeviceProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string platform = 1; */
		if (message.platform !== '') writer.tag(1, WireType.LengthDelimited).string(message.platform);
		/* string os_version = 2; */
		if (message.osVersion !== '') writer.tag(2, WireType.LengthDelimited).string(message.osVersion);
		/* string device_model = 3; */
		if (message.deviceModel !== '')
			writer.tag(3, WireType.LengthDelimited).string(message.deviceModel);
		/* bool is_simulator = 4; */
		if (message.isSimulator !== false) writer.tag(4, WireType.Varint).bool(message.isSimulator);
		/* string app_build = 5; */
		if (message.appBuild !== '') writer.tag(5, WireType.LengthDelimited).string(message.appBuild);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkClientDeviceProto
 */
export const SparkClientDeviceProto = new SparkClientDeviceProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparkRequestLocaleProto$Type extends MessageType<SparkRequestLocaleProto> {
	constructor() {
		super('SparkRequestLocaleProto', [
			{ no: 1, name: 'language', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 2, name: 'region', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
			{ no: 3, name: 'time_zone', kind: 'scalar', T: 9 /*ScalarType.STRING*/ }
		]);
	}
	create(value?: PartialMessage<SparkRequestLocaleProto>): SparkRequestLocaleProto {
		const message = globalThis.Object.create(this.messagePrototype!);
		message.language = '';
		message.region = '';
		message.timeZone = '';
		if (value !== undefined) reflectionMergePartial<SparkRequestLocaleProto>(this, message, value);
		return message;
	}
	internalBinaryRead(
		reader: IBinaryReader,
		length: number,
		options: BinaryReadOptions,
		target?: SparkRequestLocaleProto
	): SparkRequestLocaleProto {
		let message = target ?? this.create(),
			end = reader.pos + length;
		while (reader.pos < end) {
			let [fieldNo, wireType] = reader.tag();
			switch (fieldNo) {
				case /* string language */ 1:
					message.language = reader.string();
					break;
				case /* string region */ 2:
					message.region = reader.string();
					break;
				case /* string time_zone */ 3:
					message.timeZone = reader.string();
					break;
				default:
					let u = options.readUnknownField;
					if (u === 'throw')
						throw new globalThis.Error(
							`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`
						);
					let d = reader.skip(wireType);
					if (u !== false)
						(u === true ? UnknownFieldHandler.onRead : u)(
							this.typeName,
							message,
							fieldNo,
							wireType,
							d
						);
			}
		}
		return message;
	}
	internalBinaryWrite(
		message: SparkRequestLocaleProto,
		writer: IBinaryWriter,
		options: BinaryWriteOptions
	): IBinaryWriter {
		/* string language = 1; */
		if (message.language !== '') writer.tag(1, WireType.LengthDelimited).string(message.language);
		/* string region = 2; */
		if (message.region !== '') writer.tag(2, WireType.LengthDelimited).string(message.region);
		/* string time_zone = 3; */
		if (message.timeZone !== '') writer.tag(3, WireType.LengthDelimited).string(message.timeZone);
		let u = options.writeUnknownFields;
		if (u !== false) (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
		return writer;
	}
}
/**
 * @generated MessageType for protobuf message SparkRequestLocaleProto
 */
export const SparkRequestLocaleProto = new SparkRequestLocaleProto$Type();
